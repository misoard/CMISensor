{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b588ce58",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-14T10:25:54.249543Z",
     "iopub.status.busy": "2025-07-14T10:25:54.248572Z",
     "iopub.status.idle": "2025-07-14T10:25:56.190933Z",
     "shell.execute_reply": "2025-07-14T10:25:56.189912Z"
    },
    "papermill": {
     "duration": 1.951552,
     "end_time": "2025-07-14T10:25:56.192615",
     "exception": false,
     "start_time": "2025-07-14T10:25:54.241063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_inference_server.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/data-input/label_encoder.pkl\n",
      "/kaggle/input/data-input/split_ids.pkl\n",
      "/kaggle/input/data-input/cols.pkl\n",
      "/kaggle/input/data-input/scaler.pkl\n",
      "/kaggle/input/data-input/train_torch_tensors_from_wrapper_not_split.pt\n",
      "/kaggle/input/data-input/train_metadata.csv\n",
      "/kaggle/input/models/best_model_fold_0.pth\n",
      "/kaggle/input/models/best_model_fold_1.pth\n",
      "/kaggle/input/models/best_model_fold_4.pth\n",
      "/kaggle/input/models/best_model_fold_3.pth\n",
      "/kaggle/input/models/best_model_fold_2.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3c278e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:25:56.205485Z",
     "iopub.status.busy": "2025-07-14T10:25:56.204879Z",
     "iopub.status.idle": "2025-07-14T10:26:03.331998Z",
     "shell.execute_reply": "2025-07-14T10:26:03.330939Z"
    },
    "papermill": {
     "duration": 7.135601,
     "end_time": "2025-07-14T10:26:03.333576",
     "exception": false,
     "start_time": "2025-07-14T10:25:56.197975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Using CPU.\n",
      "✓ Configuration loaded for Kaggle environment (Device: cpu)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from IPython.display import display\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import os, joblib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import butter, filtfilt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score,  recall_score\n",
    "import torch\n",
    "import polars as pl\n",
    "import glob\n",
    "\n",
    "TRAIN = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class Config: \n",
    "    \"\"\"Central configuration class for training and data parameters\"\"\"\n",
    "    \n",
    "    # Paths for Kaggle environment\n",
    "    TRAIN_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\"\n",
    "    TRAIN_DEMOGRAPHICS_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\"\n",
    "    TEST_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\"\n",
    "    TEST_DEMOGRAPHICS_PATH = \"/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\"\n",
    "    EXPORT_DIR =  \"/kaggle/input/data-input\"\n",
    "    EXPORT_MODELS_PATH = \"/kaggle/input/models\" #\"/kaggle/working/models\"  \n",
    "    os.makedirs(EXPORT_DIR, exist_ok=True)                                 \n",
    "    os.makedirs(EXPORT_MODELS_PATH, exist_ok=True)                                 \n",
    "    \n",
    "    # Training parameters\n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    PERCENTILE = 95\n",
    "    PADDING = 127\n",
    "    \n",
    "    # Feature columns\n",
    "    ACC_COLS = ['acc_x', 'acc_y', 'acc_z']\n",
    "    ROT_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    \n",
    "# Set reproducibility\n",
    "np.random.seed(Config.SEED)\n",
    "\n",
    "def reset_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def check_gpu_availability():\n",
    "\n",
    "    import torch\n",
    "    if torch.cuda.is_available(): #torch.backends.mps.is_available():\n",
    "        print(\"CUDA is available.\")\n",
    "        return 'cuda'\n",
    "    else:\n",
    "        print(\"CUDA not available. Using CPU.\")\n",
    "        return 'cpu'\n",
    "\n",
    "# Check GPU availability\n",
    "DEVICE = torch.device(check_gpu_availability())\n",
    "\n",
    "print(f\"✓ Configuration loaded for Kaggle environment (Device: {DEVICE})\")\n",
    "\n",
    "\n",
    "def clean_data(data_sequences, cols, prefix = 'both'):\n",
    "    \n",
    "    if prefix == 'both':\n",
    "        print(\"removing tof and thm missing data columns from sequences! Saving seq_id in a dic with cols to remove\")\n",
    "        tof_and_thm_cols = [col for col in cols if (col.startswith('thm') or col.startswith('tof')) ]\n",
    "    else: \n",
    "        print(f\"removing {prefix} missing data columns from sequences! Saving seq_id in a dic with cols to remove\")\n",
    "        tof_and_thm_cols = [col for col in cols if col.startswith(prefix) ]\n",
    "\n",
    "    tof_thm_nan_prefixes = {}\n",
    "    for sequence_id, sequence_data in data_sequences:\n",
    "        nan_cols = sequence_data[tof_and_thm_cols].columns[sequence_data[tof_and_thm_cols].isna().any()]\n",
    "        if nan_cols.any():\n",
    "            if (prefix == 'both' or prefix == 'tof'):\n",
    "                prefixes = set(col.rsplit(\"_\", 1)[0] for col in nan_cols if col.startswith('tof'))\n",
    "            else:\n",
    "                prefixes = set()\n",
    "            if (prefix == 'both' or prefix == 'thm'):\n",
    "                prefixes.update(set(col for col in nan_cols if col.startswith('thm')))\n",
    "\n",
    "            tof_thm_nan_prefixes[sequence_id] = prefixes\n",
    "            cols_to_drop = [col for col in sequence_data.columns if any(col.startswith(p) for p in prefixes)]\n",
    "            sequence_data = sequence_data.drop(columns=cols_to_drop)\n",
    "    print(f\"found {len(tof_thm_nan_prefixes)} sequences with missing data\")\n",
    "    return data_sequences, tof_thm_nan_prefixes\n",
    "\n",
    "def handle_missing_values_quaternions(quaternion):\n",
    "    quat_clean = quaternion.copy()\n",
    "    \n",
    "    number_of_nan = quaternion.isna().sum(axis = 1)\n",
    "    rows_with_0_nan = number_of_nan == 0\n",
    "    rows_with_1_nan = number_of_nan == 1\n",
    "    rows_with_N_nan = number_of_nan > 1\n",
    "\n",
    "    ### normalize quaternions to 1 when no NaN has been detected \n",
    "    quat_values = quaternion.loc[rows_with_0_nan].values\n",
    "    norms = np.linalg.norm(quat_values, axis = 1)\n",
    "    normalized_quats = np.zeros_like(quat_values)\n",
    "    ## for non-zero norm, normalize to 1  \n",
    "    nonzero_norms = norms > 1e-6\n",
    "    normalized_quats[nonzero_norms] = quat_values[nonzero_norms] / norms[nonzero_norms, np.newaxis]\n",
    "    ## for zero-norm, normalize to the unit quaternion\n",
    "    normalized_quats[~nonzero_norms] = [1.0, 0.0, 0.0, 0.0]\n",
    "    ##update quaternion DataFrame\n",
    "    quat_clean.loc[rows_with_0_nan] = normalized_quats\n",
    "\n",
    "    ###handle 1 missing value \n",
    "    #use |w|² + |x|² + |y|² + |z|² = 1\n",
    "    if len(quaternion[rows_with_1_nan].index.tolist()) > 0:\n",
    "        nan_columns_per_row = quaternion[rows_with_1_nan].isna().idxmax(axis=1)\n",
    "        unnorm_quat = quaternion[rows_with_1_nan].pow(2).sum(axis =1, skipna = True)\n",
    "        vals = np.sqrt(np.maximum(0, 1 - unnorm_quat))\n",
    "        for row, col, val in zip(unnorm_quat.index, nan_columns_per_row, vals):\n",
    "            if row > 0:\n",
    "                if quat_clean.loc[row - 1, col] >= 0:\n",
    "                    quat_clean.loc[row, col] = val\n",
    "                else:\n",
    "                    quat_clean.loc[row, col] = -val\n",
    "            else:\n",
    "                next_row = row + 1\n",
    "                # Go forward until a non-NaN is found or reach the end\n",
    "                while next_row < len(quat_clean) and np.isnan(quat_clean.loc[next_row, col]):\n",
    "                    next_row += 1\n",
    "                if next_row == len(quat_clean):\n",
    "                    quat_clean.loc[rows_with_1_nan] = [0, 0, 0, 0]\n",
    "                    quat_clean.loc[rows_with_1_nan, 'rot_w'] = 1\n",
    "                    break\n",
    "                else:\n",
    "                    if quat_clean.loc[next_row, col] >= 0:\n",
    "                        quat_clean.loc[row, col] = val\n",
    "                    else:\n",
    "                        quat_clean.loc[row, col] = -val\n",
    "    quat_clean.loc[rows_with_N_nan] = [0, 0, 0, 0]\n",
    "    quat_clean.loc[rows_with_N_nan, 'rot_w'] = 1\n",
    "    return quat_clean\n",
    "\n",
    "def check_missing_values_quaternion(data_sequences):\n",
    "    seq_id_quaternion_nan = []\n",
    "    check_norm_quaternion = []\n",
    "    for seq_id, data_sequence in data_sequences:\n",
    "        quaternion_cols = [col for col in data_sequence.columns if col.startswith('rot_')]\n",
    "        nan_quat_cols = data_sequence[quaternion_cols].columns[data_sequence[quaternion_cols].isna().any()]\n",
    "        normalize_quat = data_sequence[quaternion_cols].pow(2).sum(axis = 1).mean()\n",
    "        if nan_quat_cols.any():\n",
    "            #print(data_sequence[[col for col in data_sequence.columns if col.startswith('acc_')]])\n",
    "            seq_id_quaternion_nan.append(seq_id)\n",
    "        if (not nan_quat_cols.any()) and normalize_quat < 0.99:\n",
    "            check_norm_quaternion.append(seq_id)\n",
    "    print(f\"✓ number of seq_id with missing values in quaternion: {len(seq_id_quaternion_nan)}\")\n",
    "    print(f\"✓ number of unnormalized quaternions for complete quaternions: {len(check_norm_quaternion)}\")\n",
    "    return seq_id_quaternion_nan\n",
    "\n",
    "\n",
    "def regularize_quaternions_per_sequence(data_sequence):\n",
    "    data_clean = data_sequence.copy()\n",
    "    quaternion_cols = [col for col in data_sequence.columns if col.startswith('rot_')]\n",
    "    nan_quat_cols = data_sequence[quaternion_cols].columns[data_sequence[quaternion_cols].isna().any()]\n",
    "    normalize_quat = data_sequence[quaternion_cols].pow(2).sum(axis = 1).mean()  \n",
    "    if nan_quat_cols.any():\n",
    "        data_clean[quaternion_cols] = handle_missing_values_quaternions(data_sequence[quaternion_cols])\n",
    "    if (not nan_quat_cols.any()) and normalize_quat < 0.99:\n",
    "        data_clean[quaternion_cols] = handle_missing_values_quaternions(data_sequence[quaternion_cols])\n",
    "\n",
    "    ### Check failed regularization\n",
    "    nan_quat_cols_clean = data_clean[quaternion_cols].columns[data_clean[quaternion_cols].isna().any()]\n",
    "    normalize_quat_clean = data_clean[quaternion_cols].pow(2).sum(axis = 1).mean() \n",
    "    if nan_quat_cols_clean.any():\n",
    "        print(\"!!NaN values have been detected after regularisation!!\")\n",
    "    if (not nan_quat_cols_clean.any()) and normalize_quat_clean < 0.99:\n",
    "        print(\"!!Not normalized quaternions have been detected after regularisation!!\")\n",
    "    return data_clean\n",
    "\n",
    "def clean_and_check_quaternion(data):\n",
    "    data_clean = data.copy()\n",
    "    data_sequences = data_clean.groupby('sequence_id')\n",
    "    seq_id_quaternion_nan = check_missing_values_quaternion(data_sequences)\n",
    "    if len(seq_id_quaternion_nan) > 0:\n",
    "        for seq_id in seq_id_quaternion_nan:\n",
    "            data_sequence = data_sequences.get_group(seq_id)\n",
    "            idx = data_sequence.index  # Get the index of the group\n",
    "            quaternion_cols = [col for col in data_sequence.columns if col.startswith('rot_')]\n",
    "            # Apply quaternion cleaning function\n",
    "            data_clean.loc[idx, quaternion_cols] = handle_missing_values_quaternions(data_sequence[quaternion_cols])\n",
    "    ##Check quaternion\n",
    "        data_sequences = data_clean.groupby('sequence_id')\n",
    "        print(\"\")\n",
    "        print(\" --- missing values in quaternions have been handled ---\")\n",
    "        check_missing_values_quaternion(data_sequences)\n",
    "        print(\"\")\n",
    "    return data_clean\n",
    "\n",
    "def compute_acceleration_features(sequence_data):\n",
    "    sequence_data_with_acc = sequence_data.copy()\n",
    "    correct_rot_order = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "    correct_acc_order = ['acc_x', 'acc_y', 'acc_z']\n",
    "    col_acc_world = ['acc_x_world', 'acc_y_world', 'acc_z_world']\n",
    "    col_linear_acc = ['linear_acc_x', 'linear_acc_y', 'linear_acc_z']\n",
    "    col_X_world = ['X_world_x', 'X_world_y', 'X_world_z']\n",
    "    col_Y_world = ['Y_world_x', 'Y_world_y', 'Y_world_z']\n",
    "    col_Z_world = ['Z_world_x', 'Z_world_y', 'Z_world_z']\n",
    "    remove_gravity = [0, 0, 9.81]\n",
    "    \n",
    "    data_rot = sequence_data[correct_rot_order]\n",
    "    data_acc = sequence_data[correct_acc_order]\n",
    "    sensor_x = np.zeros( data_acc.to_numpy().shape )\n",
    "    sensor_y = np.zeros( data_acc.to_numpy().shape )\n",
    "    sensor_z = np.zeros( data_acc.to_numpy().shape )\n",
    "    sensor_x[:, 0] = 1\n",
    "    sensor_y[:, 1] = 1\n",
    "    sensor_z[:, 2] = 1\n",
    "    data_rot_scipy = data_rot.to_numpy() \n",
    "\n",
    "    try:\n",
    "        r = R.from_quat(data_rot_scipy)\n",
    "        sequence_data_with_acc[col_acc_world] = pd.DataFrame(r.apply(data_acc.to_numpy()) - remove_gravity)\n",
    "        sequence_data_with_acc[col_X_world] = pd.DataFrame(r.apply(sensor_x))\n",
    "        sequence_data_with_acc[col_Y_world] = pd.DataFrame(r.apply(sensor_y))\n",
    "        sequence_data_with_acc[col_Z_world] = pd.DataFrame(r.apply(sensor_z))\n",
    "        \n",
    "        gravity_in_sensor = r.apply(remove_gravity, inverse=True)\n",
    "        acc_raw = sequence_data_with_acc[correct_acc_order].values\n",
    "        linear_acc = acc_raw - gravity_in_sensor\n",
    "        sequence_data_with_acc[col_linear_acc] = linear_acc\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Warning: world accelerations failed using device accelerations, replace by device acc data\")\n",
    "        sequence_data_with_acc[col_linear_acc] = sequence_data_with_acc[correct_acc_order]\n",
    "        sequence_data_with_acc[col_acc_world] = sequence_data_with_acc[correct_acc_order]\n",
    "        sequence_data_with_acc[col_X_world] = sequence_data_with_acc[correct_acc_order]\n",
    "        sequence_data_with_acc[col_Y_world] = sequence_data_with_acc[correct_acc_order]\n",
    "        sequence_data_with_acc[col_Z_world] = sequence_data_with_acc[correct_acc_order]\n",
    "\n",
    "    sequence_data_with_acc['acc_norm_world'] =sequence_data_with_acc[col_acc_world].apply(np.linalg.norm, axis=1)\n",
    "    sequence_data_with_acc['acc_norm'] =sequence_data_with_acc[correct_acc_order].apply(np.linalg.norm, axis=1)\n",
    "    sequence_data_with_acc['linear_acc_norm'] =sequence_data_with_acc[col_linear_acc].apply(np.linalg.norm, axis=1)\n",
    "    sequence_data_with_acc['acc_norm_jerk'] = sequence_data_with_acc['acc_norm'].diff().fillna(0)\n",
    "    sequence_data_with_acc['linear_acc_norm_jerk'] =  sequence_data_with_acc['linear_acc_norm'].diff().fillna(0)\n",
    "\n",
    "    return sequence_data_with_acc\n",
    "\n",
    "def compute_angular_features(sequence_data, time_delta = 10):\n",
    "    sequence_data_with_ang_vel = sequence_data.copy()\n",
    "    correct_rot_order = ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "    quats = sequence_data[correct_rot_order].values\n",
    "\n",
    "    rotations = R.from_quat(quats)\n",
    "    rotvecs = rotations.as_rotvec()\n",
    "    sequence_data_with_ang_vel[['rotvec_x', 'rotvec_y', 'rotvec_z']] = rotvecs\n",
    "    sequence_data_with_ang_vel['angle_rad'] =  sequence_data_with_ang_vel[['rotvec_x', 'rotvec_y', 'rotvec_z']].apply(np.linalg.norm, axis=1)\n",
    "    rot_diff = sequence_data_with_ang_vel[['rotvec_x', 'rotvec_y', 'rotvec_z']].diff().fillna(0)\n",
    "    sequence_data_with_ang_vel['angular_speed'] = rot_diff.pow(2).sum(axis=1).pow(0.5)\n",
    "    sequence_data_with_ang_vel['rot_angle'] = 2 * np.arccos(sequence_data['rot_w'].clip(-1, 1))\n",
    "    sequence_data_with_ang_vel['rot_angle_vel'] = sequence_data_with_ang_vel['rot_angle'].diff().fillna(0)\n",
    "    \n",
    "    n_samples = quats.shape[0]\n",
    "    ang_vel = np.zeros( (n_samples, 3))\n",
    "    ang_dist = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples - 1):\n",
    "        q1 = quats[i]\n",
    "        q2 = quats[i + 1]\n",
    "\n",
    "        if np.any(np.isnan(q1)) or np.any(np.isnan(q2)):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            r1 = R.from_quat(q1)\n",
    "            r2 = R.from_quat(q2)\n",
    "\n",
    "            # Relative rotation from q1 to q2\n",
    "            delta_r = r1.inv() * r2\n",
    "\n",
    "            # Angle of rotation (in radians)\n",
    "            ang_vel[i, : ] =  delta_r.as_rotvec()/time_delta\n",
    "            ang_dist[i] = np.linalg.norm(delta_r.as_rotvec())\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    sequence_data_with_ang_vel[['ang_vel_x', 'ang_vel_y', 'ang_vel_z']] = ang_vel\n",
    "    sequence_data_with_ang_vel['ang_dist'] = ang_dist\n",
    "\n",
    "    return sequence_data_with_ang_vel\n",
    "\n",
    "def fft_gesture(signal):\n",
    "    \"\"\"\n",
    "    Compute the normalized power in a band around a target frequency.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: 1D array-like signal\n",
    "    - freq: frequency of interest (Hz)\n",
    "    - sampling_rate: sampling rate in Hz\n",
    "    - bandwidth_ratio: fraction of freq to define integration window (e.g., 0.05 for ±5%)\n",
    "\n",
    "    Returns:\n",
    "    - normalized_band_power: power in [freq ± bandwidth] / total power\n",
    "    \"\"\"\n",
    "    signal = np.asarray(signal)\n",
    "    n = len(signal)\n",
    "    #freqs = np.fft.rfftfreq(n, d=1./sampling_rate)\n",
    "    fft_vals = np.fft.rfft(signal)\n",
    "    power_spectrum = np.abs(fft_vals)**2 / n\n",
    "    return power_spectrum / np.sum(power_spectrum)\n",
    "\n",
    "def compute_fft_features(sequence_data):\n",
    "    sequence_data_fft = sequence_data.copy()\n",
    "    fft_to_compute = [\n",
    "        'acc_x', 'acc_y', 'acc_z',\n",
    "        'linear_acc_x', 'linear_acc_y', 'linear_acc_z',\n",
    "        'rotvec_x', 'rotvec_y', 'rotvec_z',\n",
    "        'ang_vel_x', 'ang_vel_y', 'ang_vel_z',\n",
    "        'acc_norm', 'angle_rad'\n",
    "    ]\n",
    "    check_quat = ['rot_x', 'rot_y', 'rot_z']\n",
    "    phase_gesture = sequence_data['phase_adj'] == 1    \n",
    "    for feat in fft_to_compute:\n",
    "        signal = sequence_data.loc[phase_gesture, feat].to_numpy()\n",
    "        if sequence_data[check_quat].apply(np.linalg.norm, axis=1).mean() < 1e-6:\n",
    "            signal_fft_pad = np.zeros_like(sequence_data[feat])\n",
    "        else:\n",
    "            signal_fft = fft_gesture( (signal - np.mean(signal))/np.std(signal) )\n",
    "            signal_fft_pad =np.pad(signal_fft, (0, len(phase_gesture) - len(signal_fft)), 'constant')\n",
    "        sequence_data_fft[f'{feat}_FFT'] = signal_fft_pad\n",
    "    \n",
    "    return sequence_data_fft\n",
    "\n",
    "def get_angles(time_series, world_coord = False):\n",
    "    theta, phi = [], []\n",
    "    acc_features = ['acc_norm', 'acc_x', 'acc_y', 'acc_z']\n",
    "    f_phi, f_theta = 'phi', 'theta'\n",
    "    if world_coord:\n",
    "        add_name = '_world'\n",
    "        acc_features = [f + add_name for f in acc_features]\n",
    "        f_phi, f_theta = f_phi + add_name, f_theta + add_name\n",
    "\n",
    "    #numpy_time_series = time_series[acc_features].to_numpy()\n",
    "    for a, ax, ay, az in zip(*time_series[acc_features].to_numpy().T):\n",
    "        # Avoid division by zero\n",
    "        # if a < 0:\n",
    "        #     print(a)\n",
    "        th = np.arccos(np.clip(az / (a + 1e-8), -1.0, 1.0))  # polar angle\n",
    "        ph = np.arctan2(ay, ax)  # azimuthal angle\n",
    "        theta.append(th)\n",
    "        phi.append(ph)\n",
    "    time_series[f_theta] = np.array(theta)\n",
    "    time_series[f_phi] = np.array(phi)\n",
    "    return time_series\n",
    "\n",
    "def autocorr_frequency(signal, sampling_rate=1.0, min_lag=2, max_lag=None):\n",
    "    \"\"\"\n",
    "    Estimate the dominant frequency in a signal using autocorrelation.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: list or np.array of values\n",
    "    - sampling_rate: Hz\n",
    "    - min_lag: minimum lag to consider (to skip lag 0 and noise)\n",
    "    - max_lag: optional max lag to consider\n",
    "\n",
    "    Returns:\n",
    "    - dominant_freq: float or None (in Hz)\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    if len(signal) < min_lag + 2:\n",
    "        return 0.\n",
    "\n",
    "    # Normalize and detrend\n",
    "    signal = signal - np.mean(signal)\n",
    "    autocorr = np.correlate(signal, signal, mode='full')\n",
    "    autocorr = autocorr[len(autocorr)//2:]  # Keep only non-negative lags\n",
    "    autocorr /= autocorr[0]  # Normalize\n",
    "\n",
    "    # Define lag range to search\n",
    "    if max_lag is None:\n",
    "        max_lag = len(signal) #// 2\n",
    "\n",
    "    search_range = autocorr[min_lag:max_lag]\n",
    "\n",
    "    # Find peaks in the autocorrelation\n",
    "    peaks, _ = find_peaks(search_range)\n",
    "\n",
    "    if len(peaks) < 2:\n",
    "        return 0.\n",
    "\n",
    "    first_peak_lag = (peaks[-1] - peaks[0])/(len(peaks)-1)  # adjust for sliced lag\n",
    "    period = first_peak_lag / sampling_rate\n",
    "    freq = 1.0 / period\n",
    "\n",
    "    return freq\n",
    "\n",
    "def remove_frequency_component(signal, freq, sampling_rate, bandwidth=1.0, order=4):\n",
    "    \"\"\"\n",
    "    Remove a specific frequency component using a Butterworth band-stop filter.\n",
    "\n",
    "    Parameters:\n",
    "    - signal: np.array of the signal values\n",
    "    - freq: the target frequency to remove (Hz)\n",
    "    - sampling_rate: the sampling rate of the signal (Hz)\n",
    "    - bandwidth: the width of the stop band (Hz)\n",
    "    - order: filter order (higher = steeper filter)\n",
    "\n",
    "    Returns:\n",
    "    - filtered_signal: the signal with the frequency component removed\n",
    "    \"\"\"\n",
    "    bandwidth = 1 * freq\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    low = (freq - bandwidth / 2) / nyquist\n",
    "    high = (freq + bandwidth / 2) / nyquist\n",
    "\n",
    "    if low <= 0 or high >= 1:\n",
    "        # Invalid range – don't apply filtering\n",
    "        return signal.copy()\n",
    "\n",
    "    # Create band-stop filter\n",
    "    b, a = butter(order, [low, high], btype='bandstop')\n",
    "\n",
    "    # Calculate required padding length\n",
    "    padlen = 3 * max(len(a), len(b))\n",
    "\n",
    "    if len(signal) <= padlen:\n",
    "        # Too short for reliable filtering\n",
    "        b, a = butter(order, [low, high], btype='bandstop')\n",
    "        padlen = 3 * max(len(a), len(b))\n",
    "        filtered_signal = filtfilt(b, a, signal, padlen=min(padlen, len(signal) - 1))\n",
    "        # if len(signal) <= padlen:\n",
    "        #     print(\"short\")\n",
    "        #     return signal.copy()\n",
    "    else:\n",
    "        filtered_signal = filtfilt(b, a, signal)\n",
    "\n",
    "    return filtered_signal\n",
    "\n",
    "def compute_theta_phi_features(sequence_data):\n",
    "    sequence_data_theta_phi = sequence_data.copy()\n",
    "        \n",
    "    sequence_data_theta_phi = get_angles(sequence_data_theta_phi)\n",
    "    sequence_data_theta_phi = get_angles(sequence_data_theta_phi, world_coord=True)\n",
    "\n",
    "    signal_phi = sequence_data_theta_phi['phi_world'].to_numpy()\n",
    "    \n",
    "    dym_zero_cross = np.zeros(len(signal_phi))\n",
    "    window_size = 10\n",
    "    for i in range(window_size, len(signal_phi)):\n",
    "        window_phi = signal_phi[i-window_size: i]\n",
    "        dym_zero_cross[i] = np.sum(np.diff(np.signbit(window_phi)).astype(int))\n",
    "\n",
    "    sequence_data_theta_phi['zero_crossings_phi_dyn'] = dym_zero_cross\n",
    "    return sequence_data_theta_phi\n",
    "\n",
    "def compute_corr_and_svd_features(sequence_data):\n",
    "    sequence_data_with_corr_and_svd = sequence_data.copy()\n",
    "\n",
    "    svd_axis = [\n",
    "        ['acc_x', 'acc_y', 'acc_z'],\n",
    "        ['linear_acc_x', 'linear_acc_y', 'linear_acc_z'],\n",
    "        ['rotvec_x', 'rotvec_y', 'rotvec_z'],\n",
    "        ['ang_vel_x', 'ang_vel_y', 'ang_vel_z']\n",
    "    ]\n",
    "    corr_features = [\n",
    "        ('acc_x', 'acc_y'),\n",
    "        ('acc_x', 'acc_z'),\n",
    "        ('acc_y', 'acc_z'),\n",
    "        ('linear_acc_x', 'linear_acc_y'),\n",
    "        ('linear_acc_x', 'linear_acc_z'),\n",
    "        ('linear_acc_y', 'linear_acc_z'),\n",
    "        ('ang_vel_x', 'ang_vel_y'),\n",
    "        ('ang_vel_x', 'ang_vel_z'),\n",
    "        ('ang_vel_y', 'ang_vel_z'),\n",
    "        ('rotvec_x', 'rotvec_y'),\n",
    "        ('rotvec_x', 'rotvec_z'),\n",
    "        ('rotvec_y', 'rotvec_z'),\n",
    "        ('acc_norm', 'angle_rad'),\n",
    "        ('acc_x', 'rotvec_x'),\n",
    "        ('acc_x', 'rotvec_y'),\n",
    "        ('acc_x', 'rotvec_z'),\n",
    "        ('acc_y', 'rotvec_x'),\n",
    "        ('acc_y', 'rotvec_y'),\n",
    "        ('acc_y', 'rotvec_z'),\n",
    "        ('acc_z', 'rotvec_x'),\n",
    "        ('acc_z', 'rotvec_y'),\n",
    "        ('acc_z', 'rotvec_z'),\n",
    "        ('theta', 'phi'),\n",
    "        ('theta_world', 'phi_world')\n",
    "    ]\n",
    "\n",
    "    for main_axes in svd_axis:\n",
    "        #svd_features = [f + '_svd' for f in main_axes]\n",
    "        principal_axis_features = [f + '_contribution_main_axis' for f in main_axes]\n",
    "\n",
    "        name = '_'.join(main_axes[0].split('_')[:-1])\n",
    "        svd_ratio_features = [f'{name}_ratio_svd_{i}' for i in range(len(main_axes[1:]))]\n",
    "        svd_features = [f'{name}_svd_{i}' for i in range(len(main_axes))]\n",
    "\n",
    "        acc_vec = sequence_data[main_axes].to_numpy()\n",
    "\n",
    "        window_size = 10\n",
    "        sv =  np.zeros( (3, len(acc_vec)) )\n",
    "        sv_ratio = np.zeros( (2, len(acc_vec)) )\n",
    "        principal_axis = np.zeros( (3, len(acc_vec)) )\n",
    "        for i in range(window_size, len(acc_vec)):\n",
    "            window = acc_vec[i-window_size: i]\n",
    "            U, S, Vt = np.linalg.svd(window - window.mean(axis = 0))\n",
    "            principal_axis[:, i] =  Vt[0] ** 2\n",
    "            sv[:, i] = S\n",
    "            sv_ratio[0, i] = S[1]/S[0]\n",
    "            sv_ratio[1, i] = S[2]/S[0]\n",
    "\n",
    "        sequence_data_with_corr_and_svd[svd_features] = sv.T        \n",
    "        sequence_data_with_corr_and_svd[principal_axis_features] = principal_axis.T\n",
    "        sequence_data_with_corr_and_svd[svd_ratio_features] = sv_ratio.T \n",
    "\n",
    "    phase_transition = sequence_data['phase_adj'] == 0\n",
    "    phase_gesture = sequence_data['phase_adj'] == 1\n",
    "\n",
    "    #f_freq = [f for f in sequence_data.columns if ('acc' in f) or ('rotvec' in f) or ('angle_rad' in f) or ('phi' in f) or ('theta' in f) or ('ang_vel' in f)]\n",
    "    f_freq = [f for f in sequence_data.columns if any(substr in f for substr in ['acc', 'rotvec', 'angle_rad', 'phi', 'theta', 'angle_vel'])]\n",
    "\n",
    "    for f in f_freq:\n",
    "        f0_series = np.zeros(len(sequence_data))\n",
    "        f1_series = np.zeros(len(sequence_data))\n",
    "        ratio_freq = np.zeros(len(sequence_data))\n",
    "        if phase_gesture.sum() > 1:  \n",
    "            extracted_sig = sequence_data.loc[phase_gesture, f]\n",
    "            f0 = autocorr_frequency(extracted_sig, sampling_rate=10)\n",
    "            if f0 > 0:\n",
    "                residual = remove_frequency_component(extracted_sig, f0, sampling_rate=10)\n",
    "                f1 = autocorr_frequency(residual, sampling_rate=10)\n",
    "                ratio_freq[phase_gesture] = f1 / f0\n",
    "\n",
    "            else:\n",
    "                f1 = 0.\n",
    "                ratio_freq[phase_gesture] = 0.\n",
    "\n",
    "            f0_series[phase_gesture] = f0\n",
    "            f1_series[phase_gesture] = f1\n",
    "            \n",
    "        else:\n",
    "            f0_series[phase_gesture] = 0.\n",
    "            f1_series[phase_gesture] = 0.\n",
    "            ratio_freq[phase_gesture] = 0.\n",
    "\n",
    "        sequence_data_with_corr_and_svd[f'{f}_f0'] = f0_series\n",
    "        sequence_data_with_corr_and_svd[f'{f}_f1'] = f1_series\n",
    "        sequence_data_with_corr_and_svd[f'{f}_ratio_freqs'] = ratio_freq\n",
    "\n",
    "\n",
    "    for sig1, sig2 in corr_features:\n",
    "        # Initialize correlation series\n",
    "        corr_series = np.zeros(len(sequence_data))\n",
    "\n",
    "        if phase_transition.sum() > 1:  \n",
    "            corr_trans = sequence_data.loc[phase_transition, sig1].corr(sequence_data.loc[phase_transition, sig2])\n",
    "            corr_series[phase_transition] = corr_trans\n",
    "        else:\n",
    "            corr_series[phase_transition] = 0. \n",
    "\n",
    "        if phase_gesture.sum() > 1:\n",
    "            corr_gest = sequence_data.loc[phase_gesture, sig1].corr(sequence_data.loc[phase_gesture, sig2])\n",
    "            corr_series[phase_gesture] = corr_gest\n",
    "        else:\n",
    "            corr_series[phase_gesture] = 0.\n",
    "\n",
    "        # Save in your dataframe\n",
    "        sequence_data_with_corr_and_svd[f'{sig1}_{sig2}_corr'] = corr_series\n",
    "\n",
    "    return sequence_data_with_corr_and_svd\n",
    "\n",
    "def add_gesture_phase(sequence_data):\n",
    "    sequence_data_phase = sequence_data.copy()\n",
    "    length_sequence = len(sequence_data)\n",
    "    idx_transition = int( 0.45 * length_sequence)\n",
    "    phase = np.zeros(length_sequence)\n",
    "    phase[idx_transition:] = 1.\n",
    "    sequence_data_phase['phase_adj'] = phase\n",
    "    return sequence_data_phase\n",
    "\n",
    "def manage_tof(sequence_data):\n",
    "    sequence_data_tof = sequence_data.copy()\n",
    "    #tof_col = []\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f for f in sequence_data.columns if f'tof_{i}' in f]\n",
    "        tof_data = sequence_data[pixel_cols].replace(-1, np.nan)\n",
    "        sequence_data_tof[f'tof_{i}_mean'] = sequence_data[pixel_cols].mean(axis = 1)\n",
    "        sequence_data_tof[f'tof_{i}_std'] = sequence_data[pixel_cols].std(axis = 1)\n",
    "        sequence_data_tof[f'tof_{i}_min'] = tof_data.min(axis = 1)\n",
    "        sequence_data_tof[f'tof_{i}_max'] = tof_data.max(axis = 1)\n",
    "    return sequence_data_tof\n",
    "\n",
    "# def add_correlations_tof_imu(sequence_data):\n",
    "\n",
    "def split_into_transition_and_gesture_phases(sequence_data, meta_cols):\n",
    "    sequence_data_split = sequence_data.copy()\n",
    "    df_transition = sequence_data[sequence_data['phase_adj'] == 0].drop(columns='phase_adj')\n",
    "    df_gesture = sequence_data[sequence_data['phase_adj'] == 1].drop(columns='phase_adj')\n",
    "\n",
    "    # Rename columns\n",
    "    df_transition = df_transition.add_suffix('_transition')\n",
    "    df_gesture = df_gesture.add_suffix('_gesture')\n",
    "\n",
    "    # Pad shorter DataFrame with NaNs to match the longer one\n",
    "    max_len = max(len(df_transition), len(df_gesture))\n",
    "\n",
    "    df_transition = df_transition.reset_index(drop=True).reindex(range(max_len))\n",
    "    df_gesture = df_gesture.reset_index(drop=True).reindex(range(max_len))\n",
    "\n",
    "    # Concatenate along columns\n",
    "    df_combined = pd.concat([df_transition, df_gesture], axis=1)\n",
    "    # Drop transition versions of meta columns\n",
    "    df_combined.drop(columns=[col + '_transition' for col in meta_cols], inplace=True)\n",
    "    # Rename gesture versions of meta columns back to original names\n",
    "    df_combined.rename(columns={col + '_gesture': col for col in meta_cols}, inplace=True)\n",
    "\n",
    "    sequence_data_split = df_combined.fillna(0)\n",
    "    return sequence_data_split\n",
    "\n",
    "\n",
    "def wrapper_data( TRAIN = True, split = False):\n",
    "    if TRAIN:\n",
    "        train_df = pd.read_csv(Config.TRAIN_PATH)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        train_df['gesture_id'] = label_encoder.fit_transform(train_df['gesture'].astype(str))\n",
    "        joblib.dump(label_encoder, os.path.join(Config.EXPORT_DIR, \"label_encoder.pkl\"))\n",
    "\n",
    "        gesture_id_to_gestures = {idx: cl for idx, cl in enumerate(label_encoder.classes_)}\n",
    "\n",
    "        gesture_to_seq_ids = (\n",
    "            train_df.groupby('gesture_id')['sequence_id']\n",
    "            .unique()\n",
    "            .apply(list)\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        seq_type_to_seq_ids = (\n",
    "            train_df.groupby('sequence_type')['sequence_id']\n",
    "            .unique()\n",
    "            .apply(list)\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        train_sequence_subject = {\n",
    "            seq_id: sequence['subject'].iloc[0]\n",
    "            for seq_id, sequence in train_df.groupby('sequence_id')\n",
    "        }\n",
    "\n",
    "        train_sequence_ids = sorted(train_df['sequence_id'].unique())\n",
    "\n",
    "\n",
    "        train_cols = set(train_df.columns)\n",
    "\n",
    "\n",
    "        # Group by sequence_id for training data - need to include gesture column for labels\n",
    "        train_cols = train_cols + ['gesture_id'] if 'gesture_id' not in train_cols else train_cols\n",
    "\n",
    "        print(\"Handle quaternion missing values in the train dataset...\")\n",
    "        train_df_clean = clean_and_check_quaternion(train_df[list(train_cols)])\n",
    "\n",
    "\n",
    "        train_sequences = train_df_clean.groupby('sequence_id')\n",
    "\n",
    "\n",
    "        split_ids = {\n",
    "            'classes': gesture_id_to_gestures,\n",
    "            'train': {\n",
    "                'train_sequence_ids': train_sequence_ids, ##List of all train ids\n",
    "                'train_sequence_subject': train_sequence_subject, ##List of all train subject\n",
    "                'gesture_to_seq_ids': gesture_to_seq_ids, ##dic by gesture\n",
    "                'seq_type_to_seq_ids': seq_type_to_seq_ids ##dic by sequence_type\n",
    "            },\n",
    "        }\n",
    "        # Save\n",
    "        with open(os.path.join(Config.EXPORT_DIR, 'split_ids.pkl'), 'wb') as f:\n",
    "            pickle.dump(split_ids, f)\n",
    "        \n",
    "\n",
    "        ### FEATURES ####\n",
    "        meta_cols = sorted(['gesture', 'gesture_id', 'sequence_type', 'behavior', 'orientation',\n",
    "                    'row_id', 'subject', 'phase', 'sequence_id', 'sequence_counter'])\n",
    "        train_df_clean[meta_cols].to_csv( os.path.join(Config.EXPORT_DIR, 'train_metadata.csv' ))\n",
    "\n",
    "        features_cols = [c for c in train_cols if c not in meta_cols]\n",
    "        print(\"adding new features...\")\n",
    "        processed_sequences = []\n",
    "        for _, data_sequence in tqdm(train_sequences, desc=\"Processing Sequences\"):\n",
    "            data_sequence = data_sequence.reset_index(drop=True)\n",
    "            data_sequence = add_gesture_phase(data_sequence)\n",
    "            data_sequence = compute_acceleration_features(data_sequence)\n",
    "            data_sequence = compute_angular_features(data_sequence)\n",
    "            #data_sequence = compute_fft_features(data_sequence)\n",
    "            #data_sequence = compute_theta_phi_features(data_sequence)\n",
    "            #data_sequence = compute_corr_and_svd_features(data_sequence)\n",
    "            data_sequence = manage_tof(data_sequence)\n",
    "\n",
    "            if split:\n",
    "                data_sequence = split_into_transition_and_gesture_phases(data_sequence, meta_cols)\n",
    "\n",
    "            #print(data_sequence[['acc_x_transition', 'acc_x_gesture']])\n",
    "\n",
    "            processed_sequences.append(data_sequence)\n",
    "    \n",
    "        train_df_clean = pd.concat(processed_sequences).sort_index()\n",
    "\n",
    "        train_cols = train_df_clean.columns\n",
    "        #new_features = [c for c in cols if c not in features_cols and c not in meta_cols]\n",
    "        features_cols = [c for c in train_cols if c not in meta_cols]\n",
    "        imu_cols  = sorted([c for c in features_cols if not (c.startswith('thm_') or c.startswith('tof_'))])\n",
    "        tof_cols  = sorted([c for c in features_cols if c.startswith('tof_')])\n",
    "        thm_cols  = sorted([c for c in features_cols if c.startswith('thm_')])\n",
    "\n",
    "        fixed_order_features = np.concatenate( (imu_cols, thm_cols, tof_cols) )\n",
    "\n",
    "\n",
    "        print(f\"all features have been generated\")\n",
    "        # global scaler\n",
    "        #features_to_exclude = [f for f in fixed_order_features if ('svd' in f) or ('contribution_main_axis' in f) or ('f0' in f)]  # for example\n",
    "        features_to_exclude = [f for f in fixed_order_features if any(substr in f for substr in ['phase_adj'])]\n",
    "        features_to_scale = [f for f in fixed_order_features if f not in features_to_exclude]\n",
    "        print(features_to_scale)\n",
    "        all_features = np.concatenate( (meta_cols, fixed_order_features) )\n",
    "        \n",
    "        for f in train_df_clean.columns:\n",
    "            if f not in all_features:\n",
    "                print(f)\n",
    "\n",
    "        train_df_clean = train_df_clean[all_features]\n",
    "\n",
    "        scaler = StandardScaler().fit(train_df_clean[features_to_scale].to_numpy())\n",
    "        joblib.dump(scaler, os.path.join(Config.EXPORT_DIR, \"scaler.pkl\") )\n",
    "\n",
    "        train_sequences = train_df_clean.groupby('sequence_id')\n",
    "        print(train_df_clean.columns)\n",
    "\n",
    "        cols = {\n",
    "            #'train': train_cols,\n",
    "            'meta': meta_cols,\n",
    "            #'features': features_cols,\n",
    "            'imu': imu_cols,\n",
    "            'tof': tof_cols,\n",
    "            'thm': thm_cols\n",
    "        }\n",
    "        with open(os.path.join(Config.EXPORT_DIR, 'cols.pkl'), 'wb') as f:\n",
    "            pickle.dump(cols, f)\n",
    "\n",
    "\n",
    "        X, y = build_train_test_data(train_sequences, cols)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "\n",
    "def get_info(data_sequences, demograph, seq_id, print_data = False):\n",
    "    # Filter rows with the given sequence_id\n",
    "    #seq_id = 'SEQ_051475'\n",
    "    sequence_data = data_sequences.get_group(seq_id)\n",
    "\n",
    "    subject_id = sequence_data['subject'].iloc[0]\n",
    "    subject_demographics = demograph[demograph['subject'] == subject_id]\n",
    "\n",
    "    seq_info = sequence_data[\n",
    "        [\"sequence_id\", \"subject\", \"orientation\", \"gesture\", \"gesture_id\", \"sequence_type\"]\n",
    "    ].head(1).squeeze() \n",
    "    demo_info = subject_demographics[\n",
    "        [\"adult_child\", \"age\", \"sex\", \"handedness\", 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n",
    "    ].head(1).squeeze()\n",
    "    demo_info[\"adult_child\"] = {0: \"child\", 1: \"adult\"}.get(demo_info[\"adult_child\"], \"unknown\")\n",
    "    demo_info[\"sex\"] = {0: \"female\", 1: \"male\"}.get(demo_info[\"sex\"], \"unknown\")\n",
    "    demo_info[\"handedness\"] = {0: \"left-handed\", 1: \"right-handed\"}.get(demo_info[\"handedness\"], \"unknown\")\n",
    "    combined = pd.concat([seq_info, demo_info])\n",
    "    if print_data:\n",
    "        display(combined.to_frame(name='Value'))\n",
    "    return combined\n",
    "\n",
    "def get_info_v2(demograph, seq_id, seq_id_to_subject, print_data = False):\n",
    "    subject_id = seq_id_to_subject[seq_id]\n",
    "    subject_demographics = demograph[demograph['subject'] == subject_id]\n",
    "\n",
    "    demo_info = subject_demographics[\n",
    "        [\"adult_child\", \"age\", \"sex\", \"handedness\", 'height_cm', 'shoulder_to_wrist_cm', 'elbow_to_wrist_cm']\n",
    "    ].head(1).squeeze()\n",
    "    demo_info[\"adult_child\"] = {0: \"child\", 1: \"adult\"}.get(demo_info[\"adult_child\"], \"unknown\")\n",
    "    demo_info[\"sex\"] = {0: \"female\", 1: \"male\"}.get(demo_info[\"sex\"], \"unknown\")\n",
    "    demo_info[\"handedness\"] = {0: \"left-handed\", 1: \"right-handed\"}.get(demo_info[\"handedness\"], \"unknown\")\n",
    "    if print_data:\n",
    "        display(demo_info.to_frame(name='Value'))\n",
    "    return demo_info\n",
    "\n",
    "\n",
    "def pad_and_truncate(X_batch, maxlen, padding_value=0.0, dtype=torch.float32):\n",
    "    padded_batch = []\n",
    "    for seq in X_batch:\n",
    "        seq = torch.tensor(seq, dtype=dtype)\n",
    "        length = seq.size(0)\n",
    "\n",
    "        # Truncate\n",
    "        if length > maxlen:\n",
    "            seq = seq[:maxlen]\n",
    "        # Pad\n",
    "        elif length < maxlen:\n",
    "            pad_len = maxlen - length\n",
    "            padding = torch.full((pad_len, *seq.shape[1:]), padding_value, dtype=dtype)\n",
    "            seq = torch.cat([seq, padding], dim=0)\n",
    "\n",
    "        padded_batch.append(seq)\n",
    "\n",
    "    return torch.stack(padded_batch)  # [batch_size, maxlen, features]\n",
    "\n",
    "def build_train_test_data(data_sequences, cols, mask_gesture = False):\n",
    "    X_batch, y_batch, len_seq = [], [], []\n",
    "    features = np.concatenate( (cols['imu'], cols['thm'], cols['tof']) )\n",
    "    features_to_exclude = [f for f in features if any(substr in f for substr in ['phase_adj'])]\n",
    "    features_to_scale = [f for f in features if f not in features_to_exclude]\n",
    "\n",
    "    idx_to_scale = np.where(np.isin(features, features_to_scale))[0]\n",
    "    #idx_to_exclude = np.where(np.isin(features, features_to_exclude))[0]\n",
    "\n",
    "    seq_ids = []\n",
    "    for seq_id, data_sequence in data_sequences:\n",
    "        if mask_gesture:\n",
    "            gesture_phase = data_sequence['phase'] == 'Gesture'\n",
    "            sequence = data_sequence[features][gesture_phase]\n",
    "        else:\n",
    "            sequence = data_sequence[features]\n",
    "        \n",
    "        sequence = sequence.to_numpy()\n",
    "\n",
    "        # Fit and transform only those columns\n",
    "        scaler = joblib.load( os.path.join(Config.EXPORT_DIR, \"scaler.pkl\") )\n",
    "        if len(sequence) > 0:\n",
    "            sequence[:, idx_to_scale] =  scaler.transform(sequence[:, idx_to_scale])\n",
    "\n",
    "        #print(sequence[['linear_acc_ratio_svd_0', 'linear_acc_ratio_svd_1']])\n",
    "        #cols_to_scale = [c for c in cols['imu'] if c.startswith('acc_')]\n",
    "        #sequence[cols_to_scale] = scaler.fit_transform(sequence[cols_to_scale])\n",
    "\n",
    "        X_batch.append(sequence)\n",
    "        seq_ids.append(seq_id)\n",
    "        y_batch.append(data_sequence['gesture_id'].iloc[0])\n",
    "        len_seq.append(len(sequence))\n",
    "\n",
    "    ### labels one-hot categorical ###\n",
    "    y_final = torch.tensor(y_batch)\n",
    "    #y_final = F.one_hot(y_torch, num_classes = num_classes).float()\n",
    "    \n",
    "    ### pad and truncate sequences to the 95 percentile\n",
    "    pad_len_seq = int(np.percentile(len_seq, Config.PERCENTILE))\n",
    "    X_final = pad_and_truncate(X_batch, maxlen=pad_len_seq)\n",
    "\n",
    "    return X_final, y_final #, seq_ids\n",
    "\n",
    "\n",
    "### COMPETITION METRIC ###\n",
    "\n",
    "def competition_metric(y_true, y_pred) -> tuple:\n",
    "    \"\"\"Calculate the competition metric (Binary F1 + Macro F1) / 2\"\"\"\n",
    "    BFRB_gesture = [0, 1, 3, 4, 6, 7, 9, 10]\n",
    "    #non_BFRB_gesture = [2, 5, 8, 11, 12, 13, 14, 15, 16, 17]\n",
    "     \n",
    "    # Binary F1: BFRB vs non-BFRB\n",
    "    binary_f1 = f1_score(\n",
    "        np.where(np.isin(y_true, BFRB_gesture), 1, 0),\n",
    "        np.where(np.isin(y_pred, BFRB_gesture), 1, 0),\n",
    "        zero_division=0.0,\n",
    "    )\n",
    "\n",
    "    binary_recall =  recall_score(\n",
    "        np.where(np.isin(y_true, BFRB_gesture), 1, 0),\n",
    "        np.where(np.isin(y_pred, BFRB_gesture), 1, 0),\n",
    "        zero_division=0.0,\n",
    "    )\n",
    "    \n",
    "    # Macro F1: specific gesture classification (only for BFRB gestures)\n",
    "    macro_f1 = f1_score(\n",
    "        np.where(np.isin(y_true, BFRB_gesture), y_true, 99),  # Map non-BFRB to 99\n",
    "        np.where(np.isin(y_pred, BFRB_gesture), y_pred, 99),  # Map non-BFRB to 99\n",
    "        average=\"macro\", \n",
    "        zero_division=0.0,\n",
    "    )\n",
    "    \n",
    "    # Final competition score\n",
    "    final_score = 0.5 * (binary_f1 + macro_f1)\n",
    "    \n",
    "    return final_score, binary_recall, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4d0182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:26:03.346392Z",
     "iopub.status.busy": "2025-07-14T10:26:03.345939Z",
     "iopub.status.idle": "2025-07-14T10:26:03.433410Z",
     "shell.execute_reply": "2025-07-14T10:26:03.432479Z"
    },
    "papermill": {
     "duration": 0.096356,
     "end_time": "2025-07-14T10:26:03.435071",
     "exception": false,
     "start_time": "2025-07-14T10:26:03.338715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "class Conv1DAutoencoder(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_dim = 16, latent_dim=32, drop = 0.3):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 4 * hidden_dim, kernel_size=5, stride=4, padding=2),  # -> (B, 32, L/2)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.Conv1d(4 * hidden_dim, 2 * hidden_dim, kernel_size=5, stride=4, padding=2),           # -> (B, 64, L/4)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.Conv1d(2* hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),          # -> (B, 128, L/8)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2),              #nn.AdaptiveAvgPool1d(1),                                         # -> (B, 128, 1)\n",
    "        )\n",
    "        self.latent = nn.Linear(28 * hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 28 * hidden_dim) # (B, 128)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(hidden_dim, hidden_dim, kernel_size=5, stride=2, padding=2, output_padding=1),  #(B, 64, 11)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.ConvTranspose1d(hidden_dim, 2 * hidden_dim, kernel_size=5, stride=2, padding=2, output_padding=1),   # (B, 64, 41)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.ConvTranspose1d(2 * hidden_dim, 4 * hidden_dim, kernel_size=5, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = drop),\n",
    "            nn.ConvTranspose1d(4 * hidden_dim, input_channels, kernel_size=5, stride=4, padding=2, output_padding=1),\n",
    "            #nn.Tanh()  # Assuming normalized input\n",
    "        )\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = z.reshape(z.shape[0], -1)\n",
    "        z = self.latent(z)\n",
    "        x_recon = self.decoder_fc(z)\n",
    "        x_recon = x_recon.unsqueeze(-1).reshape(-1, self.hidden_dim, 28)\n",
    "        #print(x_recon.shape)\n",
    "        x_recon = self.decoder(x_recon)\n",
    "        return x_recon\n",
    "\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(p = 0.3),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, F]\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out: [B, T, H]\n",
    "\n",
    "        attn_scores = self.attn(lstm_out).squeeze(-1)  # [B, T]\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)  # [B, T]\n",
    "\n",
    "        # Weighted sum\n",
    "        context = torch.sum(lstm_out * attn_weights.unsqueeze(-1), dim=1)  # [B, H]\n",
    "\n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, hidden_dim, bias_strength = 5.):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(hidden_dim, 1, kernel_size=1)\n",
    "        )\n",
    "        self.bias_strength = bias_strength\n",
    "        self.weights = None\n",
    "\n",
    "    def forward(self, x, phase_adj = None):\n",
    "        # x: [B, hidden_dim, T]\n",
    "        scores = self.attn(x).squeeze(1)  # [B, T]\n",
    "\n",
    "        if phase_adj is not None:\n",
    "            #bias = (phase_adj.float() * self.bias_strength)  # [B, T]\n",
    "            scores = scores #+ bias\n",
    "\n",
    "        weights = F.softmax(scores, dim=1)  # [B, T]\n",
    "        self.weights = weights\n",
    "        pooled = torch.sum(x * weights.unsqueeze(1), dim=2)  # [B, hidden_dim]\n",
    "        return pooled\n",
    "\n",
    "class IMUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(), #inplace=True\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(p=0.3), \n",
    "            #nn.MaxPool1d(kernel_size=2, stride=2),  # halves time length\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            #nn.MaxPool1d(kernel_size=2, stride=2),   # halves again → total /4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, input_dim] → [B, input_dim, T]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.net(x)  # [B, hidden_dim, T]\n",
    "        return out\n",
    "\n",
    "class OptionalEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: [B, T, input_dim] → [B, input_dim, T]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.net(x)  # [B, hidden_dim, T/4]\n",
    "\n",
    "        # Adjust mask accordingly by downsampling (average pooling)\n",
    "        # mask: [B, T]\n",
    "        mask = mask.unsqueeze(1).float()  # [B, 1, T]\n",
    "        mask = F.avg_pool1d(mask, kernel_size=2, stride=2)  # [B, 1, T/2]\n",
    "        mask = F.avg_pool1d(mask, kernel_size=2, stride=2)  # [B, 1, T/4]\n",
    "        mask = mask.squeeze(1)  # [B, T/4]\n",
    "\n",
    "        out = out * mask.unsqueeze(1)  # [B, hidden_dim, T/4]\n",
    "\n",
    "        # Normalize by sum of mask per timestep (avoid div zero)\n",
    "        norm = mask.sum(dim=1, keepdim=True).clamp(min=1e-6)  # [B, 1]\n",
    "        out = out / norm.unsqueeze(1)  # broadcast on hidden_dim\n",
    "\n",
    "        return out\n",
    "\n",
    "class TabularEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "    def forward(self, x, seq_len):\n",
    "        # x: [B, n_feats]\n",
    "        emb = self.net(x)  # [B, hidden_dim]\n",
    "        # Expand along time dimension to [B, hidden_dim, seq_len]\n",
    "        emb = emb.unsqueeze(2).expand(-1, -1, seq_len)\n",
    "        return emb\n",
    "\n",
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_modalities):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(hidden_dim * num_modalities, num_modalities)\n",
    "\n",
    "    def forward(self, features_list):\n",
    "        # features_list: list of [B, hidden_dim, T]\n",
    "        concat = torch.cat(features_list, dim=1)  # [B, hidden_dim * M, T]\n",
    "        concat_t = concat.permute(0, 2, 1)        # [B, T, hidden_dim * M]\n",
    "        gate_weights = torch.sigmoid(self.gate(concat_t))  # [B, T, M]\n",
    "\n",
    "        gated_feats = []\n",
    "        for i, f in enumerate(features_list):\n",
    "            f_t = f.permute(0, 2, 1)  # [B, T, hidden_dim]\n",
    "            w = gate_weights[:, :, i].unsqueeze(-1)  # [B, T, 1]\n",
    "            gated_feats.append(f_t * w)\n",
    "        fused = sum(gated_feats)  # [B, T, hidden_dim]\n",
    "        return fused.permute(0, 2, 1)  # [B, hidden_dim, T]\n",
    "\n",
    "class GestureClassifier(nn.Module):\n",
    "    def __init__(self, imu_dim, hidden_dim, num_classes, tof_dim = None, thm_dim = None): # tabular_dim = None\n",
    "        super().__init__()\n",
    "\n",
    "        if tof_dim is None:\n",
    "            tof_dim = imu_dim\n",
    "        if thm_dim is None:\n",
    "            thm_dim = imu_dim\n",
    "        # if tabular_dim is None:\n",
    "        #     tabular_dim = imu_dim\n",
    "\n",
    "        self.imu_encoder = IMUEncoder(imu_dim, hidden_dim)\n",
    "        self.tof_encoder = OptionalEncoder(tof_dim, hidden_dim)\n",
    "        self.thm_encoder = OptionalEncoder(thm_dim, hidden_dim)\n",
    "        #self.tabular_encoder = TabularEncoder(tabular_dim, hidden_dim)\n",
    "        self.fusion = GatedFusion(hidden_dim, num_modalities=3)\n",
    "\n",
    "        self.classifier_rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.3),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            #nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, imu, tof=None, thm=None): #, tabular_feats=None\n",
    "        B, T, _ = imu.shape\n",
    "\n",
    "        imu_feat = self.imu_encoder(imu)  # [B, hidden_dim, T/4]\n",
    "\n",
    "        if tof is None:\n",
    "            tof = torch.zeros_like(imu)\n",
    "            tof_mask = torch.zeros(B, T, device=imu.device)\n",
    "        else:\n",
    "            tof_mask = (~torch.isnan(tof).any(dim=2)).float()\n",
    "\n",
    "        if thm is None:\n",
    "            thm = torch.zeros_like(imu)\n",
    "            thm_mask = torch.zeros(B, T, device=imu.device)\n",
    "        else:\n",
    "            thm_mask = (~torch.isnan(thm).any(dim=2)).float()\n",
    "\n",
    "        tof_feat = self.tof_encoder(tof, tof_mask)  # [B, hidden_dim, T/4]\n",
    "        thm_feat = self.thm_encoder(thm, thm_mask)  # [B, hidden_dim, T/4]\n",
    "\n",
    "        # if tabular_feats is None:\n",
    "        #     tabular_feats = torch.zeros(B, self.tabular_encoder.net[0].in_features, device=imu.device)\n",
    "\n",
    "        # tab_feat = self.tabular_encoder(tabular_feats, imu_feat.shape[2])  # expand to [B, hidden_dim, T/4]\n",
    "\n",
    "        fused =  self.fusion([imu_feat, tof_feat, thm_feat])  # [B, hidden_dim, T/4]\n",
    "\n",
    "        fused_t = fused.permute(0, 2, 1)  # [B, T/4, hidden_dim]\n",
    "\n",
    "        rnn_out, _ = self.classifier_rnn(fused_t)  # [B, T/4, hidden_dim*2]\n",
    "\n",
    "        pooled = rnn_out.mean(dim=1)#   # [B, hidden_dim*2]\n",
    "        pooled = F.dropout(pooled, p=0.5, training=self.training) \n",
    "\n",
    "        out = self.classifier_head(pooled)  # [B, num_classes]\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class MiniGestureClassifier(nn.Module):\n",
    "    def __init__(self, imu_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.imu_encoder = IMUEncoder(imu_dim, hidden_dim)\n",
    "        self.attn_pool = AttentionPooling(hidden_dim)\n",
    "    \n",
    "\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.3),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            #nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, imu, return_attention=False): #, phase_adj = None,\n",
    "        B, T, _ = imu.shape\n",
    "\n",
    "        imu_feat = self.imu_encoder(imu)  # [B, hidden_dim, T]\n",
    "\n",
    "        pooled = imu_feat.mean(dim=2)#   # [B, hidden_dim]\n",
    "\n",
    "        #pooled = self.attn_pool(imu_feat)\n",
    "\n",
    "        out = self.classifier_head(pooled)  # [B, num_classes]\n",
    "\n",
    "        return (out, self.attn_pool.weights) if return_attention else out\n",
    "    \n",
    "class MiniGestureLSTMClassifier(nn.Module):\n",
    "    def __init__(self, imu_dim, imu_dim_lstm, hidden_dim, lstm_hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.imu_encoder = IMUEncoder(imu_dim, hidden_dim)\n",
    "        self.lstm_attn = LSTMWithAttention(imu_dim_lstm, lstm_hidden_dim)\n",
    "        \n",
    "        fused_dim = hidden_dim + lstm_hidden_dim\n",
    "\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Linear(fused_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.3),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            #nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, imu): #, phase_adj = None,\n",
    "        #B, T, _ = imu.shape\n",
    "\n",
    "        imu_cnn_out = self.imu_encoder(imu)  # [B, hidden_dim, T]\n",
    "        imu_pooled = imu_cnn_out.mean(dim=2) # [B, hidden_dim]\n",
    "        imu_lstm_out = self.lstm_attn(imu)  # [B, H]\n",
    "\n",
    "        fused = torch.cat([imu_pooled, imu_lstm_out], dim=1)  # [B, hidden_dim + H]\n",
    "        out = self.classifier_head(fused)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, mode='max', restore_best_weights=True, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.verbose = verbose\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, current_score, model):\n",
    "        if self.mode == 'max':\n",
    "            score_improved = self.best_score is None or current_score > self.best_score\n",
    "        else:  # 'min'\n",
    "            score_improved = self.best_score is None or current_score < self.best_score\n",
    "\n",
    "        if score_improved:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            if self.restore_best_weights:\n",
    "                self.best_model_state = model.state_dict()\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: Improvement found, saving model with score {current_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping: No improvement for {self.counter} epoch(s)\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(\"EarlyStopping: Stopping early.\")\n",
    "                if self.restore_best_weights and self.best_model_state is not None:\n",
    "                    model.load_state_dict(self.best_model_state)\n",
    "\n",
    "\n",
    "\n",
    "class SensorDataset(Dataset):\n",
    "    def __init__(self, X, y, imu_dim, alpha = None, augment = None, training = True):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.alpha = alpha\n",
    "        self.augment = augment\n",
    "        self.training = training\n",
    "        self.imu_dim = imu_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, y1 = self.X[idx], self.y[idx]\n",
    "        y1_onehot = torch.nn.functional.one_hot(y1, num_classes=18).float()\n",
    "\n",
    "        if self.training and self.augment:\n",
    "            x1 = x1.numpy().copy()\n",
    "            x1 = self.augment(x1, imu_dim = self.imu_dim)\n",
    "            x1 = torch.tensor(x1,  dtype=torch.float32)\n",
    "            \n",
    "        if self.alpha is not None:\n",
    "            rand_idx = np.random.randint(0, len(self.X) - 1)\n",
    "            x2, y2 = self.X[rand_idx], self.y[rand_idx]\n",
    "\n",
    "            if self.training and self.augment:\n",
    "                x2 = x2.numpy().copy()\n",
    "                x2 = self.augment(x2, imu_dim=self.imu_dim)\n",
    "                x2 = torch.tensor(x2, dtype=torch.float32)\n",
    "\n",
    "            y2_onehot = torch.nn.functional.one_hot(y2, num_classes=18).float()\n",
    "\n",
    "            # Generate lambda from Beta distribution and ensure alpha > 0.\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            lam = max(0, min(1, lam))\n",
    "\n",
    "            x1 = lam * x1 + (1 - lam) * x2\n",
    "            y1_onehot = lam * y1_onehot + (1 - lam) * y2_onehot\n",
    "        \n",
    "        return x1, y1_onehot\n",
    "\n",
    "class TrackingSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, base_sampler):\n",
    "        self.base_sampler = base_sampler\n",
    "        self.sampled_indices = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.sampled_indices = list(self.base_sampler)  # Store for external access\n",
    "        return iter(self.sampled_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_sampler)\n",
    "\n",
    "class DeviceRotationAugment:\n",
    "    def __init__(self,\n",
    "                X, y, seqs,       \n",
    "                seqs_by_subject,\n",
    "                selected_features,\n",
    "                x_rot_range = (0, 30), # (0, 45)\n",
    "                y_rot_range = (0, 30), # (0, 45)\n",
    "                p_rotation = 0.4,\n",
    "                small_rotation = 2\n",
    "                ):     \n",
    "        \n",
    "        self.features_to_rotate = [\n",
    "        ['acc_x', 'acc_y', 'acc_z'],\n",
    "        ['acc_x_world', 'acc_y_world', 'acc_z_world'],\n",
    "        ['linear_acc_x', 'linear_acc_y', 'linear_acc_z'],\n",
    "        ['rotvec_x', 'rotvec_y', 'rotvec_z'],\n",
    "        ['ang_vel_x', 'ang_vel_y', 'ang_vel_z'],\n",
    "        ['X_world_x', 'X_world_y', 'X_world_z'], \n",
    "        ['Y_world_x', 'Y_world_y', 'Y_world_z'],\n",
    "        ['Z_world_x', 'Z_world_y', 'Z_world_z'],\n",
    "        ['rot_x', 'rot_y', 'rot_z', 'rot_w']\n",
    "        ]\n",
    "        \n",
    "        self.seqs_by_subject = seqs_by_subject \n",
    "        self.p_rotation = p_rotation\n",
    "        self.selected_features = selected_features\n",
    "        self.x_rot_range = x_rot_range\n",
    "        self.y_rot_range = y_rot_range\n",
    "        self.small_rotation = small_rotation\n",
    "\n",
    "        self.X =  torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.seqs = seqs\n",
    "        self.count = 0\n",
    "        self.iter = 2\n",
    "\n",
    "    def random_angles_by_seq(self):\n",
    "        unique_subjects = list(self.seqs_by_subject.keys())\n",
    "        # Assign a consistent random Y angle per subject\n",
    "        subject_to_angle = {\n",
    "            subj:  np.random.uniform(*self.x_rot_range) #, np.random.uniform(*self.y_rot_range)) #np.random.choice(y_range)\n",
    "            for subj in unique_subjects\n",
    "        }\n",
    "\n",
    "        random_small_angles_by_subject = {\n",
    "            subj: np.random.uniform(-self.small_rotation, self.small_rotation, size=len(seqs))\n",
    "            for subj, seqs in self.seqs_by_subject.items()\n",
    "        }\n",
    "\n",
    "\n",
    "        subject_for_seq = {\n",
    "        seq_id: (i, subj) for subj, seq_ids in self.seqs_by_subject.items() for i, seq_id in enumerate(seq_ids)\n",
    "        }\n",
    "\n",
    "        seq_to_angle = {\n",
    "            seq_id: subject_to_angle[subj] + random_small_angles_by_subject[subj][i] #, subject_to_angle[subj][1] + random_small_angles_by_subject[subj][i])\n",
    "            for seq_id, (i, subj) in subject_for_seq.items()\n",
    "        }\n",
    "\n",
    "        return seq_to_angle\n",
    "\n",
    "    def apply_rotation(self, \n",
    "                       x: torch.tensor, \n",
    "                       ax: str, \n",
    "                       seq_id: str,\n",
    "                       seqs_to_angle) -> np.ndarray:\n",
    "        x_copy = x.numpy().copy()\n",
    "        rot_x = seqs_to_angle.get(seq_id, 0.0)\n",
    "        rot_y = rot_x\n",
    "        if ax == 'x':\n",
    "            rot = R.from_euler(ax, rot_x, degrees=True)\n",
    "        if ax == 'y':\n",
    "            rot = R.from_euler(ax, rot_y, degrees=True)\n",
    "        if ax == 'z':\n",
    "            rot = R.from_euler(ax, 180, degrees=True)\n",
    "        if ax == 'zx':\n",
    "            rot = R.from_euler('z', 180, degrees=True) *  R.from_euler('x', rot_x, degrees=True)\n",
    "        if ax == 'zy':\n",
    "            rot = R.from_euler('z', 180, degrees=True) *  R.from_euler('y', rot_y, degrees=True)\n",
    "        if ax == 'xy':\n",
    "            rot = R.from_euler('x', rot_x, degrees=True) *  R.from_euler('y', rot_y, degrees=True)\n",
    "        if ax == 'zxy':\n",
    "            rot = R.from_euler('z', 180, degrees=True) * R.from_euler('x', rot_x, degrees=True) *  R.from_euler('y', rot_y, degrees=True)\n",
    "\n",
    "        for feats in self.features_to_rotate:\n",
    "            idx_rotate = np.where(np.isin(self.selected_features, feats))[0]\n",
    "            if len(idx_rotate) == 0:\n",
    "                continue\n",
    "\n",
    "            if not any('rot_' in f for f in feats):\n",
    "                rotated = rot.apply(x_copy[:, idx_rotate])\n",
    "                x_copy[:, idx_rotate] = rotated\n",
    "            else:\n",
    "                init_quat = x_copy[:, idx_rotate]\n",
    "                mask = np.linalg.norm(init_quat, axis=1) < 1e-6\n",
    "                R_orig = R.from_quat(init_quat[~mask])\n",
    "                R_new = rot * R_orig\n",
    "                new_quat = np.zeros_like(init_quat)\n",
    "                new_quat[~mask] = R_new.as_quat()\n",
    "                x_copy[:, idx_rotate] = new_quat\n",
    "\n",
    "        return x_copy\n",
    "    \n",
    "    # ---------- master call ----------\n",
    "    def __call__(self,\n",
    "                 axes: list) -> np.ndarray:\n",
    "    \n",
    "\n",
    "        seqs_to_angle = self.random_angles_by_seq()\n",
    "        \n",
    "        augmented_X_tr = []\n",
    "        augmented_y_tr = []\n",
    "\n",
    "        for xx, yy, seq_id in zip(self.X, self.y, self.seqs):\n",
    "            augmented_X_tr.append(xx)\n",
    "            augmented_y_tr.append(yy)\n",
    "\n",
    "            # Reverse time (assuming time is dimension 0)\n",
    "            x_rotated = []\n",
    "            axes_choice = np.array(axes)\n",
    "            for i in range(self.iter): #self.iter\n",
    "                #if (np.random.random() < self.p_rotation) and (len(axes_choice) > 0):\n",
    "                ax = axes_choice[i] #np.random.choice(axes_choice)\n",
    "                x_rotated.append(self.apply_rotation(xx, ax, seq_id, seqs_to_angle)) # subject_id, subject_to_angle)\n",
    "                    #axes_choice = np.delete(axes_choice, np.where(axes_choice == ax)) \n",
    "            if len(x_rotated) > 0:\n",
    "                self.count += len(x_rotated)\n",
    "                x_rotated = [torch.tensor(x) for x in x_rotated]\n",
    "                augmented_X_tr.extend(x_rotated)\n",
    "                augmented_y_tr.extend([yy] * len(x_rotated))\n",
    "\n",
    "\n",
    "        #augmented_X_tr = torch.tensor(augmented_X_tr)\n",
    "        augmented_X_tr = torch.stack(augmented_X_tr)\n",
    "        augmented_y_tr = torch.tensor(augmented_y_tr)  # Or use torch.stack if already tensors\n",
    "\n",
    "        # X_aug = my_aug.augment(self.X.numpy())  # shape preserved\n",
    "        # y_aug = self.y.clone()          # labels remain the same\n",
    "        \n",
    "        # X_aug = torch.cat([self.X, torch.from_numpy(X_aug)], dim=0)\n",
    "        # y_aug = torch.cat([self.y, y_aug], dim=0)\n",
    "        return augmented_X_tr, augmented_y_tr, self.count\n",
    "\n",
    "\n",
    "class Augment:\n",
    "    def __init__(self,\n",
    "                 p_jitter=0.8, sigma=0.02, scale_range=[0.9,1.1],\n",
    "                 p_dropout=0.3,\n",
    "                 p_moda=0.5,\n",
    "                 drift_std=0.005,     \n",
    "                 drift_max=0.25):      \n",
    "        self.p_jitter  = p_jitter\n",
    "        self.sigma     = sigma\n",
    "        self.scale_min, self.scale_max = scale_range\n",
    "        self.p_dropout = p_dropout\n",
    "        self.p_moda    = p_moda\n",
    "\n",
    "        self.drift_std = drift_std\n",
    "        self.drift_max = drift_max\n",
    "\n",
    "\n",
    "    # ---------- Jitter & Scaling ----------\n",
    "    def jitter_scale(self, x: np.ndarray) -> np.ndarray:\n",
    "        noise  = np.random.randn(*x.shape) * self.sigma\n",
    "        scale  = np.random.uniform(self.scale_min,\n",
    "                                   self.scale_max,\n",
    "                                   size=(1, x.shape[1]))\n",
    "        return (x + noise) * scale\n",
    "\n",
    "    # ---------- Sensor Drop-out ----------\n",
    "    def sensor_dropout(self,\n",
    "                       x: np.ndarray,\n",
    "                       imu_dim: int) -> np.ndarray:\n",
    "\n",
    "        if np.random.random() < self.p_dropout:\n",
    "            x[:, imu_dim:] = 0.0\n",
    "        return x\n",
    "\n",
    "    def motion_drift(self, x: np.ndarray, imu_dim: int) -> np.ndarray:\n",
    "\n",
    "        T = x.shape[0]\n",
    "\n",
    "        drift = np.cumsum(\n",
    "            np.random.normal(scale=self.drift_std, size=(T, 1)),\n",
    "            axis=0\n",
    "        )\n",
    "        drift = np.clip(drift, -self.drift_max, self.drift_max)   \n",
    "\n",
    "        x[:, :6] += drift\n",
    "\n",
    "        if imu_dim > 6:\n",
    "            x[:, 6:imu_dim] += drift     \n",
    "        return x\n",
    "    \n",
    "\n",
    "    \n",
    "    # ---------- master call ----------\n",
    "    def __call__(self,\n",
    "                 x: np.ndarray,\n",
    "                 imu_dim: int) -> np.ndarray:\n",
    "        \n",
    "        if np.random.random() < self.p_jitter:\n",
    "            x = self.jitter_scale(x)\n",
    "\n",
    "        if np.random.random() < self.p_moda:\n",
    "            x = self.motion_drift(x, imu_dim)\n",
    "\n",
    "        x = self.sensor_dropout(x, imu_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EnsemblePredictor:\n",
    "    def __init__(self,  processing_dir, models_dir, device):\n",
    "        self.device = device\n",
    "        self.models = []\n",
    "        self.scaler = None\n",
    "        self.features = None\n",
    "        self.label_encoder = None\n",
    "        self.map_classes = None\n",
    "        self.inverse_map_classes = None\n",
    "        self.cols = None\n",
    "        self._load_models(models_dir)\n",
    "        self._load_processing(processing_dir)\n",
    "\n",
    "    def _load_models(self, models_dir):\n",
    "        model_files = sorted(glob.glob(f\"{models_dir}/best_model_fold_*.pth\"))\n",
    "        print(f\"{len(model_files)} models have been found\")\n",
    "        \n",
    "        for model_file in model_files:\n",
    "            checkpoint = torch.load(model_file, map_location=self.device, weights_only=True)\n",
    "            \n",
    "            model = MiniGestureClassifier(imu_dim=14, hidden_dim=128, num_classes=18)\n",
    "            \n",
    "            model.load_state_dict(checkpoint) #['model_state_dict']\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            self.models.append(model)\n",
    "            \n",
    "            print(f\"✅ {model_file} loaded\")\n",
    "\n",
    "    def _load_processing(self, processing_dir):\n",
    "        self.scaler = joblib.load(os.path.join(processing_dir, \"scaler.pkl\"))\n",
    "        self.label_encoder = joblib.load(os.path.join(processing_dir, \"label_encoder.pkl\"))\n",
    "        self.map_classes = {idx: cl for idx, cl in enumerate(self.label_encoder.classes_)}\n",
    "        self.inverse_map_classes = {cl: idx for idx, cl in enumerate(self.label_encoder.classes_)}\n",
    "\n",
    "        \n",
    "        file_path_cols = os.path.join(processing_dir, \"cols.pkl\")\n",
    "        with open(file_path_cols, 'rb') as f:\n",
    "            self.cols = pickle.load(f)\n",
    "        self.features = np.concatenate( (self.cols['imu'], self.cols['thm'], self.cols['tof']) ) \n",
    "\n",
    "        print(\"-> scaler, features, labels classes loaded\")\n",
    "        #print(f\"features = {self.features}\")\n",
    "    \n",
    "    def features_eng(self, df_seq: pd.DataFrame):\n",
    "        df_seq = regularize_quaternions_per_sequence(df_seq)\n",
    "\n",
    "        ### -- ADD NEW FEATURES (IMU + AVERAGED TOF COLUMNS) --- \n",
    "        df_seq = df_seq.reset_index(drop=True)\n",
    "        df_seq = add_gesture_phase(df_seq)\n",
    "        df_seq = compute_acceleration_features(df_seq)\n",
    "        df_seq = compute_angular_features(df_seq)\n",
    "        df_seq = manage_tof(df_seq)\n",
    "        return df_seq\n",
    "    \n",
    "    def scale_pad_and_transform_to_torch_sequence(self, df_seq, pad_length, is_imu_only = True):\n",
    "        ### -- Columns re-ordering to match train order\n",
    "        df_seq_features = df_seq[self.features].copy()\n",
    "\n",
    "        #has_nan_tof_thm = df_seq_features[ np.concatenate( (self.cols['tof'], self.cols['thm']) ) ].isnull().all(axis=1).all()\n",
    "        # if has_nan_tof_thm:\n",
    "        #     print(\"NaN values have been found in TOF and/or THM data\")\n",
    "        \n",
    "        has_nan_imu = df_seq_features[self.cols['imu']].isnull().any().any()\n",
    "        if has_nan_imu:\n",
    "            print(\"x IMU cols have NaN values. Shouldn't be the case! Check data!\")\n",
    "\n",
    "        ### -- Scale features and check NaN for IMU COLS  \n",
    "        np_seq_features  =  df_seq_features.to_numpy()\n",
    "        features_to_exclude = [f for f in self.features if any(substr in f for substr in ['phase_adj'])]\n",
    "        features_to_scale = [f for f in self.features if f not in features_to_exclude]\n",
    "        idx_to_scale = np.where(np.isin(self.features, features_to_scale))[0]\n",
    "        if len(np_seq_features) > 0:\n",
    "            np_seq_features[:, idx_to_scale] =  self.scaler.transform(np_seq_features[:, idx_to_scale])\n",
    "\n",
    "\n",
    "        if is_imu_only:\n",
    "            imu_features = [\n",
    "            'acc_x','acc_y','acc_z', 'rotvec_x', 'rotvec_y', 'rotvec_z', \n",
    "            'linear_acc_x', 'linear_acc_y', 'linear_acc_z', \n",
    "            'ang_vel_x', 'ang_vel_y', 'ang_vel_z', 'ang_dist',\n",
    "            'phase_adj'\n",
    "            ] \n",
    "            idx_imu = [np.where(self.features == f)[0][0] for f in imu_features]    ### select features from selected_features above\n",
    "            np_seq_features = np_seq_features[:, idx_imu]\n",
    "\n",
    "\n",
    "        seq = torch.tensor(np_seq_features, dtype=torch.float32)\n",
    "        length = seq.size(0)\n",
    "        # Truncate\n",
    "        if length >= pad_length:\n",
    "            seq = seq[:pad_length].unsqueeze(0)\n",
    "        # Pad\n",
    "        elif length < pad_length:\n",
    "            pad_len = pad_length - length\n",
    "            padding = torch.full((pad_len, *seq.shape[1:]), 0.0, dtype=torch.float32)\n",
    "            seq = torch.cat([seq, padding], dim=0).unsqueeze(0)\n",
    "\n",
    "        #print(f\"sequence has been scaled and padded. shape (1, T, F): {seq.shape}\")\n",
    "        return seq.to(self.device)\n",
    "\n",
    "\n",
    "    def predict(self, torch_seq, by_fold = None):\n",
    "    # torch_seq: [N, ...]  (N = batch size)\n",
    "\n",
    "        if by_fold is None:\n",
    "            pred_by_model = []\n",
    "    \n",
    "            for model in self.models:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    output = model(torch_seq)  # [N, num_classes]\n",
    "                    preds = output.argmax(1).cpu().numpy()  # shape: [N]\n",
    "                    pred_by_model.append(preds)  # list of arrays\n",
    "        \n",
    "            # Transpose to get predictions per sample:\n",
    "            # pred_by_model: list of model predictions → shape: [num_models, N]\n",
    "            # after zip(*...), we get: [ [model1_pred_sample1, model2_pred_sample1, ...], ... ]\n",
    "            pred_by_model = list(zip(*pred_by_model))  # shape: [N, num_models]\n",
    "        \n",
    "            final_preds = []\n",
    "            for sample_preds in pred_by_model:\n",
    "                most_common_prediction = Counter(sample_preds).most_common(1)[0][0]\n",
    "                final_preds.append(str(self.map_classes[most_common_prediction]))\n",
    "        else:\n",
    "            model = self.models[by_fold]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                output = model(torch_seq)  # [N, num_classes]\n",
    "                preds = output.argmax(1).cpu().numpy()  # shape: [N]\n",
    "            final_preds = [str(self.map_classes[pred]) for pred in preds]\n",
    "        \n",
    "        if len(final_preds) == 1:\n",
    "            return final_preds[0]\n",
    "        else:\n",
    "            return final_preds  # length N list of mapped predictions\n",
    "\n",
    "        \n",
    "    #def predict(self, torch_seq):\n",
    "        #pred_by_model = []\n",
    "        #for model in self.models:\n",
    "        ##model = predictor.models[0]\n",
    "        #    with torch.no_grad():\n",
    "        #        output = model(torch_seq)\n",
    "        #        pred = output.argmax(1).cpu().numpy()[0]\n",
    "        ## if seq_id == 'SEQ_000007':\n",
    "        ##     print(pred)\n",
    "        ##     break\n",
    "        #        pred_by_model.append(pred)\n",
    "        #most_common_prediction = Counter(pred_by_model).most_common(1)[0][0]\n",
    "        #return self.map_classes[most_common_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cdf611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:26:03.446575Z",
     "iopub.status.busy": "2025-07-14T10:26:03.446251Z",
     "iopub.status.idle": "2025-07-14T10:26:03.464019Z",
     "shell.execute_reply": "2025-07-14T10:26:03.463093Z"
    },
    "papermill": {
     "duration": 0.025515,
     "end_time": "2025-07-14T10:26:03.465550",
     "exception": false,
     "start_time": "2025-07-14T10:26:03.440035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs, device, class_weight, bfrb_classes, patience = 50, fold = None):\n",
    "    model.to(device)\n",
    "    early_stopper = EarlyStopping(patience=patience, mode='max', restore_best_weights=True, verbose=True)\n",
    "\n",
    "    best_score = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            # print(targets[:5])\n",
    "            # print(inputs[0, :10, 0])\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) #, phase_adj = inputs[:, :,  -1]\n",
    "            #targets = targets * (1 - 0.2) + (0.2 / len(class_weight))\n",
    "            loss = criterion(outputs, targets, class_weight, bfrb_classes)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "            train_targets.extend(targets.argmax(1).cpu().numpy())\n",
    "        \n",
    "\n",
    "        train_acc, train_binary_recall, train_macro_f1  = competition_metric(train_targets, train_preds)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        bin_preds = []\n",
    "        bin_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs) #, phase_adj = inputs[:, :,  -1]\n",
    "                loss = criterion(outputs, targets, class_weight, bfrb_classes)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(outputs.argmax(1).cpu().numpy())\n",
    "                val_targets.extend(targets.argmax(1).cpu().numpy())\n",
    "\n",
    "                mask_bfrb_classes = np.array([idx in bfrb_classes.numpy() for idx in range(len(class_weight))])\n",
    "                outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "                bin_pred = outputs[:, mask_bfrb_classes].sum(1) > 0.4 #torch.stack([, outputs[:, ~mask_bfrb_classes].sum(1)], dim=1) \n",
    "                bin_preds.extend(bin_pred.cpu().numpy())\n",
    "\n",
    "                bin_target = targets[:, mask_bfrb_classes].sum(1) #, targets[:, ~mask_bfrb_classes].sum(1)], dim=1) \n",
    "                bin_targets.extend(bin_target.cpu().numpy())\n",
    "                \n",
    "        \n",
    "        val_acc, val_binary_recall, val_macro_f1 = competition_metric(val_targets, val_preds)     #accuracy_score(val_targets, val_preds)\n",
    "        val_binary_recall = recall_score(bin_targets, bin_preds)\n",
    "        early_stopper(val_acc, model)\n",
    "        if early_stopper.best_score > best_score:\n",
    "            best_score = early_stopper.best_score\n",
    "            name = \"best_model\"\n",
    "            if fold is not None:\n",
    "                name += f\"_fold_{fold}.pth\"\n",
    "            else:\n",
    "                name += \".pth\"\n",
    "            torch.save(early_stopper.best_model_state, os.path.join(Config.EXPORT_MODELS_PATH, name ))\n",
    "\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"Training stopped early.\")\n",
    "            break\n",
    "        \n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, Bin. : {train_binary_recall:.4f}, Macro: {train_macro_f1:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, Bin. : {val_binary_recall:.4f}, Macro: {val_macro_f1:.4f}\")\n",
    "\n",
    "\n",
    "    return best_score\n",
    "\n",
    "\n",
    "def soft_cross_entropy(pred_logits, soft_targets, class_weight, bfrb_classes, gamma = 1.5):\n",
    "    mask_bfrb_classes = np.array([idx in bfrb_classes.numpy() for idx in range(len(class_weight))])\n",
    "    outputs = torch.nn.functional.softmax(pred_logits, dim=1)\n",
    "    bin_pred = torch.stack([ outputs[:, mask_bfrb_classes].sum(1), outputs[:, ~mask_bfrb_classes].sum(1)], dim=1)\n",
    "    bin_target = torch.stack([soft_targets[:, mask_bfrb_classes].sum(1), soft_targets[:, ~mask_bfrb_classes].sum(1)], dim=1) \n",
    "    \n",
    "    binary_loss = F.kl_div(\n",
    "    torch.log(bin_pred + 1e-8),  # log-probabilities\n",
    "    bin_target,\n",
    "    reduction='batchmean'\n",
    "    )\n",
    "\n",
    "    log_probs = F.log_softmax(pred_logits, dim=1)\n",
    "    #idx_bfrb_classes = bfrb_classes.numpy()\n",
    "    #soft_targets = soft_targets * class_weight.to(DEVICE).unsqueeze(0)\n",
    "    #soft_targets = soft_targets / soft_targets.sum(dim=1, keepdim=True)  # re-normalize\n",
    "    weighted_kl = F.kl_div(log_probs, soft_targets, reduction='batchmean')\n",
    "    #weighted_kl = weighted_kl * class_weight.to(DEVICE).unsqueeze(0)\n",
    "    #weighted_kl[:, idx_bfrb_classes] *=  boost_factor\n",
    "    return weighted_kl #+ gamma * binary_loss#.sum(dim = 1).mean() #\n",
    "\n",
    "\n",
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    sequence = sequence.to_pandas()\n",
    "    sequence = predictor.features_eng(sequence)\n",
    "    torch_seq = predictor.scale_pad_and_transform_to_torch_sequence(sequence, pad_length)\n",
    "    most_common_prediction = predictor.predict(torch_seq)\n",
    "    return str(most_common_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35505452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:26:03.477338Z",
     "iopub.status.busy": "2025-07-14T10:26:03.476997Z",
     "iopub.status.idle": "2025-07-14T10:26:03.488631Z",
     "shell.execute_reply": "2025-07-14T10:26:03.487726Z"
    },
    "papermill": {
     "duration": 0.01962,
     "end_time": "2025-07-14T10:26:03.490177",
     "exception": false,
     "start_time": "2025-07-14T10:26:03.470557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hierarchical macro F1 metric for the CMI 2025 Challenge.\n",
    "\n",
    "This script defines a single entry point `score(solution, submission, row_id_column_name)`\n",
    "that the Kaggle metrics orchestrator will call.\n",
    "It performs validation on submission IDs and computes a combined binary & multiclass F1 score.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    \"\"\"Errors raised here will be shown directly to the competitor.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class CompetitionMetric:\n",
    "    \"\"\"Hierarchical macro F1 for the CMI 2025 challenge.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.target_gestures = [\n",
    "            'Above ear - pull hair',\n",
    "            'Cheek - pinch skin',\n",
    "            'Eyebrow - pull hair',\n",
    "            'Eyelash - pull hair',\n",
    "            'Forehead - pull hairline',\n",
    "            'Forehead - scratch',\n",
    "            'Neck - pinch skin',\n",
    "            'Neck - scratch',\n",
    "        ]\n",
    "        self.non_target_gestures = [\n",
    "            'Write name on leg',\n",
    "            'Wave hello',\n",
    "            'Glasses on/off',\n",
    "            'Text on phone',\n",
    "            'Write name in air',\n",
    "            'Feel around in tray and pull out an object',\n",
    "            'Scratch knee/leg skin',\n",
    "            'Pull air toward your face',\n",
    "            'Drink from bottle/cup',\n",
    "            'Pinch knee/leg skin'\n",
    "        ]\n",
    "        self.all_classes = self.target_gestures + self.non_target_gestures\n",
    "\n",
    "    def calculate_hierarchical_f1(\n",
    "        self,\n",
    "        sol: pd.DataFrame,\n",
    "        sub: pd.DataFrame\n",
    "    ) -> float:\n",
    "\n",
    "        # Validate gestures\n",
    "        invalid_types = {i for i in sub['gesture'].unique() if i not in self.all_classes}\n",
    "        if invalid_types:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Invalid gesture values in submission: {invalid_types}\"\n",
    "            )\n",
    "\n",
    "        # Compute binary F1 (Target vs Non-Target)\n",
    "        y_true_bin = sol['gesture'].isin(self.target_gestures).values\n",
    "        y_pred_bin = sub['gesture'].isin(self.target_gestures).values\n",
    "        f1_binary = f1_score(\n",
    "            y_true_bin,\n",
    "            y_pred_bin,\n",
    "            pos_label=True,\n",
    "            zero_division=0,\n",
    "            average='binary'\n",
    "        )\n",
    "\n",
    "        # Build multi-class labels for gestures\n",
    "        y_true_mc = sol['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "        y_pred_mc = sub['gesture'].apply(lambda x: x if x in self.target_gestures else 'non_target')\n",
    "\n",
    "        # Compute macro F1 over all gesture classes\n",
    "        f1_macro = f1_score(\n",
    "            y_true_mc,\n",
    "            y_pred_mc,\n",
    "            average='macro',\n",
    "            zero_division=0\n",
    "        )\n",
    "\n",
    "        return 0.5 * f1_binary + 0.5 * f1_macro\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    row_id_column_name: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute hierarchical macro F1 for the CMI 2025 challenge.\n",
    "\n",
    "    Expected input:\n",
    "      - solution and submission as pandas.DataFrame\n",
    "      - Column 'sequence_id': unique identifier for each sequence\n",
    "      - 'gesture': one of the eight target gestures or \"Non-Target\"\n",
    "\n",
    "    This metric averages:\n",
    "    1. Binary F1 on SequenceType (Target vs Non-Target)\n",
    "    2. Macro F1 on gesture (mapping non-targets to \"Non-Target\")\n",
    "\n",
    "    Raises ParticipantVisibleError for invalid submissions,\n",
    "    including invalid SequenceType or gesture values.\n",
    "\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> solution = pd.DataFrame({'id': range(4), 'gesture': ['Eyebrow - pull hair']*4})\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Forehead - pull hairline']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.5\n",
    "    >>> submission = pd.DataFrame({'id': range(4), 'gesture': ['Text on phone']*4})\n",
    "    >>> score(solution, submission, row_id_column_name=row_id_column_name)\n",
    "    0.0\n",
    "    >>> score(solution, solution, row_id_column_name=row_id_column_name)\n",
    "    1.0\n",
    "    \"\"\"\n",
    "    # Validate required columns\n",
    "    for col in (row_id_column_name, 'gesture'):\n",
    "        if col not in solution.columns:\n",
    "            raise ParticipantVisibleError(f\"Solution file missing required column: '{col}'\")\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(f\"Submission file missing required column: '{col}'\")\n",
    "\n",
    "    metric = CompetitionMetric()\n",
    "    return metric.calculate_hierarchical_f1(solution, submission)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac44e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:26:03.501410Z",
     "iopub.status.busy": "2025-07-14T10:26:03.501106Z",
     "iopub.status.idle": "2025-07-14T10:26:15.793714Z",
     "shell.execute_reply": "2025-07-14T10:26:15.792659Z"
    },
    "papermill": {
     "duration": 12.300471,
     "end_time": "2025-07-14T10:26:15.795580",
     "exception": false,
     "start_time": "2025-07-14T10:26:03.495109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== COMMENTS ========\n",
      "Smooth target labels with eps = 0.2\n",
      "-------------------------\n",
      "\n",
      "Loading existing tensor...\n",
      "number of NaN (detect possible FE errors): 0\n",
      "Data shape (X, y): (torch.Size([8151, 127, 14]), torch.Size([8151]))\n",
      "\n",
      "===== FOLD 1/5 =====\n",
      "\n",
      "---- INFERENCE MODE ----\n",
      "5 models have been found\n",
      "✅ /kaggle/input/models/best_model_fold_0.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_1.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_2.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_3.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_4.pth loaded\n",
      "-> scaler, features, labels classes loaded\n",
      "\n",
      "===== FOLD 2/5 =====\n",
      "\n",
      "---- INFERENCE MODE ----\n",
      "5 models have been found\n",
      "✅ /kaggle/input/models/best_model_fold_0.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_1.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_2.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_3.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_4.pth loaded\n",
      "-> scaler, features, labels classes loaded\n",
      "\n",
      "===== FOLD 3/5 =====\n",
      "\n",
      "---- INFERENCE MODE ----\n",
      "5 models have been found\n",
      "✅ /kaggle/input/models/best_model_fold_0.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_1.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_2.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_3.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_4.pth loaded\n",
      "-> scaler, features, labels classes loaded\n",
      "\n",
      "===== FOLD 4/5 =====\n",
      "\n",
      "---- INFERENCE MODE ----\n",
      "5 models have been found\n",
      "✅ /kaggle/input/models/best_model_fold_0.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_1.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_2.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_3.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_4.pth loaded\n",
      "-> scaler, features, labels classes loaded\n",
      "\n",
      "===== FOLD 5/5 =====\n",
      "\n",
      "---- INFERENCE MODE ----\n",
      "5 models have been found\n",
      "✅ /kaggle/input/models/best_model_fold_0.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_1.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_2.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_3.pth loaded\n",
      "✅ /kaggle/input/models/best_model_fold_4.pth loaded\n",
      "-> scaler, features, labels classes loaded\n",
      " - Best score for fold 0: 0.7586320155088404\n",
      " - Best score for fold 1: 0.770285667602687\n",
      " - Best score for fold 2: 0.7814929815439894\n",
      " - Best score for fold 3: 0.7662584180483833\n",
      " - Best score for fold 4: 0.7476944918351994\n",
      "mean score for all folds: 0.7648727149078199\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"======== COMMENTS ========\")\n",
    "print(\"Smooth target labels with eps = 0.2\")\n",
    "print(\"-------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 250\n",
    "PATIENCE = 50\n",
    "ALPHA = 0.3\n",
    "LR = 1e-3\n",
    "\n",
    "SEED = Config.SEED\n",
    "reset_seed(SEED)\n",
    "\n",
    "file_path_train = os.path.join(Config.EXPORT_DIR, \"train_torch_tensors_from_wrapper_not_split.pt\")\n",
    "file_path_cols = os.path.join(Config.EXPORT_DIR, \"cols.pkl\")\n",
    "file_path_splits = os.path.join(Config.EXPORT_DIR, \"split_ids.pkl\")\n",
    "\n",
    "\n",
    "selected_features = [\n",
    "    'acc_x','acc_y','acc_z',#,'rot_x', 'rot_y', 'rot_z', 'rot_w', \n",
    "    'rotvec_x', 'rotvec_y', 'rotvec_z', \n",
    "    'linear_acc_x', 'linear_acc_y', 'linear_acc_z', \n",
    "    #'linear_acc_x_FFT', 'linear_acc_y_FFT', 'linear_acc_z_FFT', \n",
    "    #'acc_norm_world', \n",
    "    # 'acc_norm', 'linear_acc_norm', \n",
    "    # 'acc_norm_jerk', 'linear_acc_norm_jerk', \n",
    "    #'angle_rad', 'angular_speed', \n",
    "    # 'rot_angle', 'rot_angle_vel', 'angular_speed', \n",
    "    'ang_vel_x', 'ang_vel_y', 'ang_vel_z', 'ang_dist',\n",
    "    # 'ang_vel_x_FFT', 'ang_vel_y_FFT', 'ang_vel_z_FFT', \n",
    "    'phase_adj',\n",
    "    ] \n",
    "\n",
    "\n",
    "# ---------------- LOAD DATA ------------------------\n",
    "\n",
    "\n",
    "if os.path.exists(file_path_train):\n",
    "    print(\"Loading existing tensor...\")\n",
    "    data = torch.load(file_path_train)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "\n",
    "    with open(file_path_cols, 'rb') as f:\n",
    "        cols = pickle.load(f)\n",
    "\n",
    "    with open(file_path_splits, 'rb') as f:\n",
    "        split_ids = pickle.load(f)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"File not found. Generating data...\")\n",
    "    X_train, y_train = wrapper_data(split=False)\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "    data = {'X_train': X_train, 'y_train': y_train} \n",
    "    torch.save(data, file_path_train)\n",
    "    print(\"Data saved.\")\n",
    "\n",
    "    with open(file_path_cols, 'rb') as f:\n",
    "        cols = pickle.load(f)\n",
    "\n",
    "    with open(file_path_splits, 'rb') as f:\n",
    "        split_ids = pickle.load(f)\n",
    "\n",
    "\n",
    "gesture_mapping = {cl: idx for idx, cl in split_ids['classes'].items()}   ### GESTURE MAP CLASSES --> LABELS\n",
    "bfrb_gesture = CompetitionMetric().target_gestures                        ### TARGET GESTURE CLASSES\n",
    "bfrb_classes = torch.tensor([gesture_mapping[cl] for cl in bfrb_gesture]) ### TARGET GESTURE LABELS\n",
    "\n",
    "\n",
    "# ------------------ SELECT FEATURES AND PREPARE DATA FOR TRAINING ------------------------\n",
    "\n",
    "all_features = np.concatenate( (cols['imu'], cols['thm'], cols['tof']) ) \n",
    "\n",
    "\n",
    "idx_imu = [np.where(all_features == f)[0][0] for f in selected_features]    ### select features from selected_features above\n",
    "idx_tof = np.where(np.isin(all_features, cols['tof']))[0]                   ### TOF Features for later\n",
    "idx_thm = np.where(np.isin(all_features, cols['thm']))[0]                   ### THM Features for later\n",
    "\n",
    "X = X_train[:, :, idx_imu]   ## select idx features in X\n",
    "y = y_train                  ## labels \n",
    "\n",
    "\n",
    "#### NaN ? in DATA #### \n",
    "nan_mask = torch.isnan(X)\n",
    "nan_indices = torch.nonzero(nan_mask, as_tuple=True)\n",
    "print(f\"number of NaN (detect possible FE errors): {len(np.unique(nan_indices[0].numpy()))}\")\n",
    "      \n",
    "if len(np.unique(nan_indices[0].numpy())) > 0:      \n",
    "    X = torch.tensor(np.nan_to_num(X, nan=0.0))\n",
    "########################\n",
    "\n",
    "print(f\"Data shape (X, y): {X.shape, y.shape}\")\n",
    "\n",
    "cw_vals = compute_class_weight('balanced', classes=list(split_ids['classes'].keys()), y=y.numpy())  ## Class weights to handle imbalance\n",
    "class_weight = torch.from_numpy(cw_vals).float()                                                    ## class weights as torch tensor\n",
    "\n",
    "\n",
    "# ------------------------------- TRAINING ---------------------------------\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state = 39) #STRATIFIED k-Fold by group (subject_id)\n",
    "    \n",
    "train_ids = np.array(split_ids['train']['train_sequence_ids']) #seq_id of data sequences \n",
    "groups = [split_ids['train']['train_sequence_subject'][seq_id] for seq_id in train_ids] #subject_id of data_sequences\n",
    "    \n",
    "    # idx_spe_seq = np.where(train_ids == 'SEQ_000007')[0]\n",
    "\n",
    "\n",
    "    ### LOOP FOR EACH TRAINING FOLD\n",
    "best_scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups)):\n",
    "    print(f\"\\n===== FOLD {fold+1}/{N_SPLITS} =====\\n\")\n",
    "    reset_seed(SEED)\n",
    "    \n",
    "        # Split data\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    if TRAIN:\n",
    "        subjects_id = np.array(groups)[train_idx]\n",
    "        train_seq_ids = train_ids[train_idx]\n",
    "    \n",
    "        print(\" ---- check for reproductibility ----\")\n",
    "        print(f\"first 10 seq_id = {train_seq_ids[:10]}\")\n",
    "        print(f\"first 10 train idx = {train_idx[:10]}, and val idx = {val_idx[:10]}\")\n",
    "        print(f\"mean train idx = {np.mean(train_idx)}, and mean val idx = {np.mean(val_idx)}\\n\")\n",
    "    \n",
    "        df = pd.DataFrame({'subject_id': subjects_id, 'seq_id': train_seq_ids})\n",
    "        seqs_by_subject = (\n",
    "                df.groupby('subject_id')['seq_id']\n",
    "                .unique()\n",
    "                .apply(list)\n",
    "                .to_dict()\n",
    "            )\n",
    "\n",
    "        #### DATA AUGMENTATION #####\n",
    "        print(\"------ DATA AUGMENTATION: DEVICE ROTATION ------\")\n",
    "        rotation_augmented = DeviceRotationAugment(X_tr, y_tr, train_seq_ids,     \n",
    "                              seqs_by_subject, selected_features, p_rotation=1.1, small_rotation=2)\n",
    "        X_tr, y_tr, count = rotation_augmented(axes=['z', 'x'])\n",
    "        print(f\"number of additional rotated features samples: {count}\")\n",
    "        print(f\"shape of training data after augmentation (X, y): {X_tr.shape, y_tr.shape}\\n\")\n",
    "    \n",
    "        #augmenter = Augment()\n",
    "    \n",
    "        # augmenter = Augment(\n",
    "        #     p_jitter=0.98, sigma=0.033, scale_range=(0.75,1.16),\n",
    "        #     p_dropout=0.42,\n",
    "        #     p_moda=0.39, drift_std=0.004, drift_max=0.39    \n",
    "        # )\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        train_ds = SensorDataset(X_tr, y_tr, imu_dim = 7, alpha=ALPHA)  ### TRAINING ROTATION AUGMENTED DATA WITH MixUp \\alpha \n",
    "        # CLASS IMBALANCE handling \n",
    "        print(\" ----------- CLASS INBALANCE SAMPLER (WeightedRandomSampler) ---------\") \n",
    "        class_counts = np.bincount(y_tr.numpy())\n",
    "        print(f\"Number of samples per class: {Counter(y_tr.numpy())}\\n\")\n",
    "        class_weights = 1. / class_counts\n",
    "        sample_weights = class_weights[y_tr.numpy()]\n",
    "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights) , replacement=True)\n",
    "        tracking_sampler = TrackingSampler(sampler)\n",
    "        sampled_indices = list(sampler)\n",
    "    \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=tracking_sampler)  \n",
    "    \n",
    "    \n",
    "        val_ds = SensorDataset(X_val, y_val, imu_dim = 7, training=False) ### VALIDATION DATA (NO AUG, NO MixUp)\n",
    "        val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "        criterion = soft_cross_entropy # LOSS FUNCTION\n",
    "    \n",
    "        model = MiniGestureClassifier(imu_dim=X_tr.shape[2], hidden_dim=128, num_classes=len(class_weight)) # MODEL\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR) # OPTIMIZER\n",
    "    \n",
    "        best_score = train_model(model, train_loader, val_loader, optimizer, criterion, EPOCHS, DEVICE, class_weight, bfrb_classes, patience=PATIENCE, fold = fold)\n",
    "    else:\n",
    "        print(\"---- INFERENCE MODE ----\")\n",
    "        processing_dir = Config.EXPORT_DIR\n",
    "        models_dir = Config.EXPORT_MODELS_PATH\n",
    "        predictor = EnsemblePredictor(processing_dir, models_dir, DEVICE)\n",
    "        inverse_map_classes = predictor.inverse_map_classes\n",
    "        #map_classes = predictor.map_classes\n",
    "        \n",
    "        preds_str = predictor.predict(X_val.to(DEVICE), by_fold = fold)\n",
    "        preds_int = [inverse_map_classes[pred_str] for pred_str in preds_str]\n",
    "        best_score, _, _ = competition_metric(y_val, preds_int)\n",
    "    \n",
    "    best_scores.append(best_score)\n",
    "\n",
    "\n",
    "for fold, score in enumerate(best_scores):\n",
    "    print(f\" - Best score for fold {fold}: {score}\")\n",
    "    \n",
    "print(f\"mean score for all folds: {np.mean(best_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1dbbbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-14T10:26:15.811143Z",
     "iopub.status.busy": "2025-07-14T10:26:15.810135Z",
     "iopub.status.idle": "2025-07-14T10:26:15.823769Z",
     "shell.execute_reply": "2025-07-14T10:26:15.822864Z"
    },
    "papermill": {
     "duration": 0.023348,
     "end_time": "2025-07-14T10:26:15.825438",
     "exception": false,
     "start_time": "2025-07-14T10:26:15.802090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_test = False\n",
    "\n",
    "if dummy_test:\n",
    "\n",
    "    pad_length = Config.PADDING\n",
    "    processing_dir = Config.EXPORT_DIR\n",
    "    models_dir = Config.EXPORT_MODELS_PATH\n",
    "    test_path = Config.TEST_PATH\n",
    "    train_path = Config.TRAIN_PATH\n",
    "    train_path_demo = Config.TRAIN_DEMOGRAPHICS_PATH\n",
    "    \n",
    "    # Check GPU availability\n",
    "    DEVICE = torch.device(check_gpu_availability())\n",
    "    print(f\"✓ Configuration loaded for Kaggle environment (Device: {DEVICE})\")\n",
    "    \n",
    "    \n",
    "    predictor = EnsemblePredictor(processing_dir, models_dir, DEVICE)\n",
    "    inverse_map_classes = predictor.inverse_map_classes\n",
    "    map_classes = predictor.map_classes\n",
    "\n",
    "    train = pd.read_csv(train_path)\n",
    "    train_demo = pd.read_csv(train_path_demo)\n",
    "    \n",
    "    print(f\"---> Original shape = {train.shape}\")\n",
    "    sel_seq  = train[\"sequence_id\"].unique()#[0 : 3500]\n",
    "    seq      = sel_seq[0: 1750]\n",
    "    oth_cols = sorted([c for c in train.columns if (c.startswith('thm_') or c.startswith('tof_'))]) #train.columns[16:]\n",
    "    train    = train.loc[train.sequence_id.isin(sel_seq)]\n",
    "    train.loc[train.sequence_id.isin(seq), oth_cols] = np.nan\n",
    "    print(f\"---> Truncated shape = {train.shape}\")\n",
    "    train_sequences = train.groupby(\"sequence_id\")\n",
    "    \n",
    "    ypred = []\n",
    "    ytruth = []\n",
    "    for _, sequence in tqdm(train_sequences, desc=\"Processing Sequences\"):\n",
    "    #     #print(f\"======== SEQUENCE {seq_id} ========\")\n",
    "        sequence = pl.DataFrame(sequence)\n",
    "        pred = predict(sequence, train_demo)\n",
    "        ypred.append(inverse_map_classes[pred])\n",
    "        sequence = sequence.to_pandas()\n",
    "        ytruth.append(inverse_map_classes[sequence['gesture'].iloc[0]])\n",
    "    \n",
    "    \n",
    "    print(competition_metric(ytruth, ypred))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7860371,
     "sourceId": 12460387,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7863206,
     "sourceId": 12465227,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.224089,
   "end_time": "2025-07-14T10:26:18.307281",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-14T10:25:49.083192",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
